{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265e6f95-ba4a-466d-b071-31058775918a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fa_support\n",
    "import evall\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4e1fb7-5da9-4b87-b5ad-4fcba59f63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  np.load(\"train.npy\")\n",
    "#test = np.load(\"new_fa_test_data.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cef4df-af88-483e-a259-08148677ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [312,8,55,3,13,6, 2, 77]\n",
    "names = ['brand_id',\n",
    "         'category', 'colour', 'divisioncode', 'itemcategorycode',\n",
    "         'itemfamilycode', 'itemseason', 'productgroup']\n",
    "dic = dict(zip(names,numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae36973b-3e9c-48e2-8c55-55820e6a81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dic =pd.read_csv(\"Eval_dic_bp\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af470afe-7dd7-43d2-9342-6faa64021b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_emb_dim = sum(dic.values())\n",
    "\n",
    "D_emb_dim = 50\n",
    "\n",
    "G_emb_dim = 50\n",
    "\n",
    "hidden_dim = 64\n",
    "alpha = 0\n",
    "\n",
    "# Initializer\n",
    "init = tf.initializers.glorot_normal()\n",
    "\n",
    "'''Generator and Discriminator Attribute Embeddings'''\n",
    "#D_price_embs = tf.keras.layers.Embedding(input_dim = dic['pricetype'], output_dim = D_emb_dim,\n",
    " #                                         trainable=True, weights = [init(shape=( dic['pricetype'],D_emb_dim))])\n",
    "D_brand_embs = tf.keras.layers.Embedding(input_dim = dic['brand_id'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['brand_id'],D_emb_dim))])\n",
    "D_category_embs = tf.keras.layers.Embedding(input_dim = dic['category'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['category'],D_emb_dim))])\n",
    "D_colour_embs = tf.keras.layers.Embedding(input_dim = dic['colour'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['colour'],D_emb_dim))])\n",
    "D_div_embs = tf.keras.layers.Embedding(input_dim = dic['divisioncode'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['divisioncode'],D_emb_dim))])\n",
    "D_itemcat_embs = tf.keras.layers.Embedding(input_dim = dic['itemcategorycode'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['itemcategorycode'],D_emb_dim))])\n",
    "D_itemfam_embs = tf.keras.layers.Embedding(input_dim = dic['itemfamilycode'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['itemfamilycode'],D_emb_dim))])\n",
    "D_season_embs = tf.keras.layers.Embedding(input_dim = dic['itemseason'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['itemseason'],D_emb_dim))])\n",
    "D_prod_embs = tf.keras.layers.Embedding(input_dim = dic['productgroup'], output_dim = D_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['productgroup'],D_emb_dim))])\n",
    "\n",
    "\n",
    "#G_price_embs = tf.keras.layers.Embedding(input_dim = dic['pricetype'], output_dim = G_emb_dim,\n",
    "#                                               trainable=True, weights = [init(shape=( dic['pricetype'],G_emb_dim))])\n",
    "G_brand_embs = tf.keras.layers.Embedding(input_dim = dic['brand_id'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['brand_id'],G_emb_dim))])\n",
    "G_category_embs = tf.keras.layers.Embedding(input_dim = dic['category'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['category'],G_emb_dim))])\n",
    "G_colour_embs = tf.keras.layers.Embedding(input_dim = dic['colour'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['colour'],G_emb_dim))])\n",
    "G_div_embs = tf.keras.layers.Embedding(input_dim = dic['divisioncode'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['divisioncode'],G_emb_dim))])\n",
    "G_itemcat_embs = tf.keras.layers.Embedding(input_dim = dic['itemcategorycode'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['itemcategorycode'],G_emb_dim))])\n",
    "G_itemfam_embs = tf.keras.layers.Embedding(input_dim = dic['itemfamilycode'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['itemfamilycode'],G_emb_dim))])\n",
    "G_season_embs = tf.keras.layers.Embedding(input_dim = dic['itemseason'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['itemseason'],G_emb_dim))])\n",
    "G_prod_embs = tf.keras.layers.Embedding(input_dim = dic['productgroup'], output_dim = G_emb_dim,\n",
    "                                          trainable=True, weights = [init(shape=( dic['productgroup'],G_emb_dim))])\n",
    "\n",
    "\n",
    "# Model input sizes\n",
    "G_input_size =  G_emb_dim*8\n",
    "D_input_size = user_emb_dim + D_emb_dim*8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ff9300-5d36-427c-925d-7413485511a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator_input( brand_id, category, colour, divisioncode, itemcategorycode, itemfamilycode, itemseason, productgroup):\n",
    "    emb_dic = {}\n",
    "#    dic[\"pricetype\"] = G_brand_embs(tf.constant(pricetype))\n",
    "    dic[\"brand_id\"] = G_brand_embs(tf.constant(brand_id))\n",
    "    dic[\"category\"] = G_brand_embs(tf.constant(category))\n",
    "    dic[\"colour\"] = G_brand_embs(tf.constant(colour))\n",
    "    dic[\"divisioncode\"] = G_brand_embs(tf.constant(divisioncode))\n",
    "    dic[\"itemcategorycode\"] = G_brand_embs(tf.constant(itemcategorycode))\n",
    "    dic[\"itemfamilycode\"] = G_brand_embs(tf.constant(itemfamilycode))\n",
    "    dic[\"itemseason\"] = G_brand_embs(tf.constant(itemseason))\n",
    "    dic[\"productgroup\"] = G_brand_embs(tf.constant(productgroup))\n",
    "    emb = tf.keras.layers.concatenate(list(dic.values()), 1)\n",
    "    return emb\n",
    "def generator_input_new( brand_id, category, colour, divisioncode, itemcategorycode, itemfamilycode, itemseason, productgroup):\n",
    "    emb_dic = {}\n",
    "#    dic[\"pricetype\"] = G_brand_embs(tf.constant(pricetype))\n",
    "    dic[\"brand_id\"] = G_brand_embs( (brand_id))\n",
    "    dic[\"category\"] = G_brand_embs( (category))\n",
    "    dic[\"colour\"] = G_brand_embs( (colour))\n",
    "    dic[\"divisioncode\"] = G_brand_embs( (divisioncode))\n",
    "    dic[\"itemcategorycode\"] = G_brand_embs( (itemcategorycode))\n",
    "    dic[\"itemfamilycode\"] = G_brand_embs( (itemfamilycode))\n",
    "    dic[\"itemseason\"] = G_brand_embs( (itemseason))\n",
    "    dic[\"productgroup\"] = G_brand_embs( (productgroup))\n",
    "    emb = tf.keras.layers.concatenate(list(dic.values()), 1)\n",
    "    return emb\n",
    "\n",
    "# Generates user based on concatenation of all attributes\n",
    "def generator():\n",
    "    bc_input = tf.keras.layers.Input(shape=(G_input_size))\n",
    "    x = tf.keras.layers.Dense(hidden_dim, activation ='sigmoid', kernel_regularizer = 'l2')(bc_input)\n",
    "    x = tf.keras.layers.Dense(hidden_dim, activation ='sigmoid', kernel_regularizer = 'l2')(x)\n",
    "    x = tf.keras.layers.Dense(user_emb_dim, activation ='sigmoid', kernel_regularizer = 'l2')(x)\n",
    "    g_model = tf.keras.models.Model(bc_input, x, name = 'generator')\n",
    "    return g_model\n",
    "g_model = generator()\n",
    "\n",
    "def discriminator_input( brand_id, category, colour, divisioncode, itemcategorycode, itemfamilycode, \n",
    "                        itemseason, productgroup, user_emb):\n",
    "    emb_dic = {}\n",
    "#    dic[\"pricetype\"]  = D_brand_embs(tf.constant(pricetype))\n",
    "    dic[\"brand_id\"]  = D_brand_embs(tf.constant(brand_id))\n",
    "    dic[\"category\"]  = D_brand_embs(tf.constant(category))\n",
    "    dic[\"colour\"]  = D_brand_embs(tf.constant(colour))\n",
    "    dic[\"divisioncode\"]  = D_brand_embs(tf.constant(divisioncode))\n",
    "    dic[\"itemcategorycode\"]  = D_brand_embs(tf.constant(itemcategorycode))\n",
    "    dic[\"itemfamilycode\"]  = D_brand_embs(tf.constant(itemfamilycode))\n",
    "    dic[\"itemseason\"]  = D_brand_embs(tf.constant(itemseason))\n",
    "    dic[\"productgroup\"]  = D_brand_embs(tf.constant(productgroup))\n",
    "    user_emb = tf.cast(user_emb, dtype=float)\n",
    "    emb = tf.keras.layers.concatenate(list(dic.values()), 1)\n",
    "    final_emb = tf.keras.layers.concatenate([emb, user_emb], 1)\n",
    "    return final_emb\n",
    "def discriminator_input_new( brand_id, category, colour, divisioncode, itemcategorycode, itemfamilycode, \n",
    "                        itemseason, productgroup, user_emb):\n",
    "    emb_dic = {}\n",
    "    dic[\"brand_id\"]  = D_brand_embs( (brand_id))\n",
    "    dic[\"category\"]  = D_brand_embs( (category))\n",
    "    dic[\"colour\"]  = D_brand_embs( (colour))\n",
    "    dic[\"divisioncode\"]  = D_brand_embs( (divisioncode))\n",
    "    dic[\"itemcategorycode\"]  = D_brand_embs( (itemcategorycode))\n",
    "    dic[\"itemfamilycode\"]  = D_brand_embs( (itemfamilycode))\n",
    "    dic[\"itemseason\"]  = D_brand_embs( (itemseason))\n",
    "    dic[\"productgroup\"]  = D_brand_embs( (productgroup))\n",
    "    emb = tf.keras.layers.concatenate(list(dic.values()), 1)\n",
    "    final_emb = tf.keras.layers.concatenate([emb, user_emb], 1)\n",
    "    return final_emb\n",
    "def discriminator():\n",
    "    d_input = tf.keras.layers.Input(shape=(D_input_size))\n",
    "    x = tf.keras.layers.Dense(hidden_dim, activation ='sigmoid', kernel_regularizer = 'l2')(d_input)\n",
    "    x = tf.keras.layers.Dense(hidden_dim, activation ='sigmoid', kernel_regularizer = 'l2')(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.models.Model(d_input, x, name = 'discriminator')\n",
    "    return model\n",
    "d_model = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3bea43e-2f9e-44a8-863a-38787bb9212c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Cross entropy loss means\\ndef generator_loss(d_logits):\\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits, labels=tf.ones_like(d_logits)))\\n\\ndef discriminator_loss(real, fake):\\n    logit = tf.reduce_mean(fake-real)\\n    r = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real, labels=tf.ones_like(real)))\\n    f = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake, labels=tf.zeros_like(fake)))\\n    return r+f\\n\\ndef counter_loss(counter):\\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=counter, labels=tf.zeros_like(counter)))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Loss functions'''\n",
    "def generator_loss(fake_user):\n",
    "    return -tf.reduce_mean(fake_user)\n",
    "\n",
    "def discriminator_loss(real, fake):\n",
    "    logit = tf.reduce_mean(fake- real)\n",
    "    return logit\n",
    "\n",
    "def counter_loss(counter):\n",
    "    return tf.reduce_mean(counter)\n",
    "\n",
    "def discriminator_counter_loss(real, fake, counter):\n",
    "    logit = tf.reduce_mean(real - counter - fake)\n",
    "    return logit\n",
    "''' Cross entropy loss means\n",
    "def generator_loss(d_logits):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits, labels=tf.ones_like(d_logits)))\n",
    "\n",
    "def discriminator_loss(real, fake):\n",
    "    logit = tf.reduce_mean(fake-real)\n",
    "    r = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real, labels=tf.ones_like(real)))\n",
    "    f = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake, labels=tf.zeros_like(fake)))\n",
    "    return r+f\n",
    "\n",
    "def counter_loss(counter):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=counter, labels=tf.zeros_like(counter)))''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c903445e-c383-4471-a702-540456ebc66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_matrix = np.load(\"fa_ui_matrix.npy\")\n",
    "user_emb_matrix =  np.load(\"new_fa_ua_matrix.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2d2b58-3d17-4d9d-9b81-8e10ea450422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WGAN Class\n",
    "class WGAN(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        discriminator_extra_steps=5,\n",
    "        batch_size=100\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = d_model\n",
    "        self.generator = g_model\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.k = 10        \n",
    "        self.index = 0 \n",
    "        self.c_index = 0 \n",
    "        self.gp_weight = 10\n",
    "        self.eval_steps = 0\n",
    "        self.max_p10 = .01 \n",
    "        self.max_g10 = .01\n",
    "        self.max_m10 = .01\n",
    "        self.max_p20 = .01\n",
    "        self.max_g20 = .01\n",
    "        self.max_m20 = .01\n",
    "        self.val_losses = []\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn,c_loss_fn, run_eagerly):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.c_loss_fn = c_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.run_eagerly = run_eagerly\n",
    "\n",
    "\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_users, fake_users,  brand_id,\\\n",
    "                                    category, colour, divisioncode, itemcategorycode, itemfamilycode, \\\n",
    "                                    itemseason, productgroup):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size,1], 0.0, 1.0)\n",
    "        diff = fake_users - real_users\n",
    "        interpolated = real_users + alpha * diff\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            interpolated_input = discriminator_input(   brand_id,\\\n",
    "                                    category, colour, divisioncode, itemcategorycode, itemfamilycode, \\\n",
    "                                    itemseason, productgroup, interpolated)\n",
    "            pred = self.discriminator(interpolated_input)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = tape.gradient(pred, [interpolated])[0] +1e-10\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2) +1e-5\n",
    "        return gp\n",
    "\n",
    "    def gradient_penalty_val(self, batch_size, real_users, fake_users,  brand_id,\\\n",
    "                                    category, colour, divisioncode, itemcategorycode, itemfamilycode, \\\n",
    "                                    itemseason, productgroup):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size,1], 0.0, 1.0)\n",
    "        diff = fake_users - real_users\n",
    "        interpolated = real_users + alpha * diff\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            interpolated_input = discriminator_input_new(   brand_id,\\\n",
    "                                    category, colour, divisioncode, itemcategorycode, itemfamilycode, \\\n",
    "                                    itemseason, productgroup, interpolated)\n",
    "            pred = self.discriminator(interpolated_input)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = tape.gradient(pred, [interpolated])[0] +1e-10\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2) +1e-5\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_users):\n",
    "        self.eval_steps +=1 \n",
    "        c_batch_size = 2*self.batch_size\n",
    "        for i in range(self.d_steps):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Get batch data\n",
    "                country, postcode, loyal, gender,  brand_id, category, colour, divisioncode, \\\n",
    "                itemcategorycode, itemfamilycode, itemseason, productgroup, real_users, items = fa_support.get_batchdata(self.index, self.index + self.batch_size)\n",
    "                # Get batch of counter examples\n",
    "                counter_brand_id, counter_category, counter_colour, counter_divisioncode, \\\n",
    "                counter_itemcategorycode, counter_itemfamilycode, counter_itemseason, \\\n",
    "                counter_productgroup,  counter_users = fa_support.get_counter_batch(self.c_index, self.c_index + c_batch_size)\n",
    "                # Generate fake users from attributes\n",
    "                g_input0 = generator_input(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "                fake_users = self.generator(g_input0)\n",
    "                # Get the logits for the fake users\n",
    "                d_input0 = discriminator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup, fake_users)\n",
    "                fake_logits = self.discriminator(d_input0)\n",
    "                # Get the logits for the real user\n",
    "                d_input1 = discriminator_input(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup, real_users)\n",
    "                real_logits = self.discriminator(d_input1)\n",
    "                # Get logits for counter examples\n",
    "                \n",
    "                d_input2 = discriminator_input( counter_brand_id, counter_category, counter_colour, counter_divisioncode, \\\n",
    "                counter_itemcategorycode, counter_itemfamilycode, counter_itemseason, \\\n",
    "                counter_productgroup,  counter_users)\n",
    "                counter_logits = self.discriminator(d_input2)\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_logits, fake_logits)\n",
    "                c_loss = self.c_loss_fn(counter_logits)\n",
    "                # Get gradient penalty\n",
    "                gp = self.gradient_penalty(self.batch_size, real_users, fake_users, brand_id,\\\n",
    "                                    category, colour, divisioncode, itemcategorycode, itemfamilycode, \\\n",
    "                                    itemseason, productgroup)\n",
    "                # Later add counter loss\n",
    "                d_loss = d_cost + c_loss +1e-5  + gp*self.gp_weight \n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "            \n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Generate fake images using the generator\n",
    "            g_input1 = generator_input(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "            gen_users = self.generator(g_input1)\n",
    "            # Get the discriminator logits for fake images\n",
    "            d_input2 = discriminator_input(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup, gen_users)\n",
    "            gen_logits = self.discriminator(d_input2)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_logits) +1e-5\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        self.index = self.index +self.batch_size\n",
    "        if self.eval_steps %760==0:\n",
    "          #  val_loss = wgan.val_step(10)\n",
    "           # return {\"training_loss\": d_loss+g_loss, \"val_loss\":val_loss}\n",
    "        #else:\n",
    "        #return {\"training_loss\": d_loss}\n",
    "            p_at_10,G_at_10,M_at_10, val_p10,val_g10,val_m10 = wgan.test(10)\n",
    "            p_at_20,G_at_20,M_at_20, val_p20,val_g20,val_m20 = wgan.test(20)\n",
    "            if p_at_10 > self.max_p10:\n",
    "                self.max_p10 = p_at_10\n",
    "            if G_at_10 > self.max_g10:\n",
    "                self.max_g10 = G_at_10\n",
    "            if M_at_10 > self.max_m10:\n",
    "                self.max_m10 = M_at_10\n",
    "            if p_at_20 > self.max_p20:\n",
    "                self.max_p20 = p_at_20\n",
    "            if G_at_20 > self.max_g20:\n",
    "                self.max_g20 = G_at_20\n",
    "            if M_at_20 > self.max_m20:\n",
    "                self.max_m20 = M_at_20\n",
    "            \n",
    "            return {\"training_loss\": d_loss, \"p10\":p_at_10,\n",
    "                           \"G10\":G_at_10,\"M10\":M_at_10, \"p20\": p_at_20,\"G20\":G_at_20,\"M20\":M_at_20,\n",
    "                  \"val_p10\":val_p10,\n",
    "                           \"val_G10\":val_g10,\"val_M10\":val_m10, \"val_p20\": val_p20,\"val_G20\":val_g20,\"val_M20\":val_m20}\n",
    "        \n",
    "        else:\n",
    "            return {\"training_loss\": d_loss}\n",
    "        \n",
    "    def test(self, k):\n",
    "        \n",
    "        country, postcode, loyal, gender,  brand_id, category, colour, divisioncode, \\\n",
    "        itemcategorycode, itemfamilycode, itemseason, productgroup, item, user, user_emb = fa_support.get_testdata(0,5000)\n",
    "        \n",
    "        test_BATCH_SIZE = country.size\n",
    "        g_input1 = generator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "        gen_users = self.generator(g_input1)\n",
    "        sim_users = fa_support.get_intersection_similar_user(gen_users, k)\n",
    "\n",
    "        count = 0\n",
    "        for i, user_list in zip(item, sim_users):       \n",
    "            for u in user_list:\n",
    "                if ui_matrix[u,i] == 1:\n",
    "                    count = count + 1            \n",
    "        p_at_k = round(count/(test_BATCH_SIZE * k), 4)\n",
    "\n",
    "        RS = []\n",
    "        ans = 0.0\n",
    "        for i, user_list in zip(item, sim_users):           \n",
    "            r=[]\n",
    "            for user in user_list:\n",
    "                 r.append(ui_matrix[user][i])\n",
    "            ans = ans + evall.ndcg_at_k(r, k, method=1)\n",
    "            RS.append(r)\n",
    "        G_at_k = ans/test_BATCH_SIZE\n",
    "        M_at_k = evall.mean_average_precision(RS)\n",
    "        \n",
    "        country, postcode, loyal, gender,  brand_id, category, colour, divisioncode, \\\n",
    "        itemcategorycode, itemfamilycode, itemseason, productgroup, item, user, user_emb = fa_support.get_testdata(5000,10000)\n",
    "        \n",
    "        test_BATCH_SIZE = country.size\n",
    "        g_input1 = generator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "        gen_users = self.generator(g_input1)\n",
    "        sim_users = fa_support.get_intersection_similar_user(gen_users, k)\n",
    "\n",
    "        count = 0\n",
    "        for i, user_list in zip(item, sim_users):       \n",
    "            for u in user_list:\n",
    "                if ui_matrix[u,i] == 1:\n",
    "                    count = count + 1            \n",
    "        val_p_at_k = round(count/(test_BATCH_SIZE * k), 4)\n",
    "\n",
    "        RS = []\n",
    "        ans = 0.0\n",
    "        for i, user_list in zip(item, sim_users):           \n",
    "            r=[]\n",
    "            for user in user_list:\n",
    "                 r.append(ui_matrix[user][i])\n",
    "            ans = ans + evall.ndcg_at_k(r, k, method=1)\n",
    "            RS.append(r)\n",
    "        val_G_at_k = ans/test_BATCH_SIZE\n",
    "        val_M_at_k = evall.mean_average_precision(RS)\n",
    "       \n",
    "       \n",
    "\n",
    "        return p_at_k,G_at_k,M_at_k, val_p_at_k, val_G_at_k, val_M_at_k\n",
    "    \n",
    "    def test_step(self,data):\n",
    "        for i in range(self.d_steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                brand_id = data[0][:,0] \n",
    "                category = data[0][:,1]\n",
    "                colour = data[0][:,2] \n",
    "                divisioncode = data[0][:,3] \n",
    "                itemcategorycode = data[0][:,4] \n",
    "                itemfamilycode = data[0][:,5] \n",
    "                itemseason = data[0][:,6] \n",
    "                productgroup = data[0][:,7] \n",
    "                user_emb = tf.cast(data[1],dtype=float)\n",
    "\n",
    "                counter_brand_id, counter_category, counter_colour, counter_divisioncode, \\\n",
    "                counter_itemcategorycode, counter_itemfamilycode, counter_itemseason, \\\n",
    "                counter_productgroup,  counter_users = fa_support.get_val_counter_batch(0,10000)\n",
    "\n",
    "\n",
    "                country, postcode, loyal, gender,  brand_id, category, colour, divisioncode, \\\n",
    "                itemcategorycode, itemfamilycode, itemseason, productgroup, item, user, user_emb = fa_support.get_testdata(5000,10000)\n",
    "\n",
    "\n",
    "\n",
    "                g_input1 = generator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                                   itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "\n",
    "                gen_users = self.generator(g_input1)\n",
    "                d_input0 = discriminator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup, gen_users)\n",
    "                fake_logits = self.discriminator(d_input0)\n",
    "                # Get the logits for the real user\n",
    "                d_input1 = discriminator_input(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup, user_emb)\n",
    "                real_logits = self.discriminator(d_input1)\n",
    "                d_input2 = discriminator_input( counter_brand_id, counter_category, counter_colour, counter_divisioncode, \\\n",
    "                    counter_itemcategorycode, counter_itemfamilycode, counter_itemseason, \\\n",
    "                    counter_productgroup,  counter_users)\n",
    "                counter_logits = self.discriminator(d_input2)\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                c_loss = self.c_loss_fn(counter_logits)\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_logits, fake_logits)\n",
    "                # Get gradient penalty\n",
    "                gp = self.gradient_penalty(5000, user_emb, gen_users, brand_id,\\\n",
    "                                    category, colour, divisioncode, itemcategorycode, itemfamilycode, \\\n",
    "                                    itemseason, productgroup)\n",
    "                # Later add counter loss\n",
    "                d_loss = d_cost  +c_loss +1e-5  + gp*self.gp_weight \n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Generate fake images using the generator\n",
    "            g_input1 = generator_input_new(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "            gen_users = self.generator(g_input1)\n",
    "            # Get the discriminator logits for fake images\n",
    "            d_input2 = discriminator_input_new(  brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup, gen_users)\n",
    "            gen_logits = self.discriminator(d_input2)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_logits) +1e-5\n",
    "        \n",
    "        val_loss =  d_loss\n",
    "        return {\"val_loss\":val_loss}\n",
    "    \n",
    "    \n",
    "    def recommend(self, input_data, k):\n",
    "        country, postcode, loyal, gender,  brand_id, category, colour, divisioncode, \\\n",
    "        itemcategorycode, itemfamilycode, itemseason, productgroup, item, user = input_data\n",
    "        \n",
    "        test_BATCH_SIZE = country.size\n",
    "        g_input1 = generator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "        gen_users = self.generator(g_input1)\n",
    "        sim_users = fa_support.get_intersection_similar_user(gen_users, k)\n",
    "        return sim_users\n",
    "    def evaluate_sample(self, input_data, k):\n",
    "        country, postcode, loyal, gender,  brand_id, category, colour, divisioncode, \\\n",
    "        itemcategorycode, itemfamilycode, itemseason, productgroup, item, user = input_data\n",
    "        \n",
    "        test_BATCH_SIZE = country.size\n",
    "        g_input1 = generator_input( brand_id, category, colour, divisioncode, \\\n",
    "                                           itemcategorycode, itemfamilycode, itemseason, productgroup)\n",
    "        gen_users = self.generator(g_input1)\n",
    "        sim_users = fa_support.get_intersection_similar_user(gen_users, k)\n",
    "        count = 0\n",
    "\n",
    "        count = 0\n",
    "        for i, user_list in zip(item, sim_users):       \n",
    "            for u in user_list:\n",
    "                if ui_matrix[u,i] == 1:\n",
    "                    count = count + 1            \n",
    "        p_at_k = round(count/(test_BATCH_SIZE * k), 4)\n",
    "\n",
    "        RS = []\n",
    "        ans = 0.0\n",
    "        for i, user_list in zip(item, sim_users):           \n",
    "            r=[]\n",
    "            for user in user_list:\n",
    "                 r.append(ui_matrix[user][i])\n",
    "            ans = ans + evall.ndcg_at_k(r, k, method=1)\n",
    "            RS.append(r)\n",
    "        G_at_k = ans/test_BATCH_SIZE\n",
    "        M_at_k = evall.mean_average_precision(RS)\n",
    "       \n",
    "\n",
    "        return p_at_k,G_at_k,M_at_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b80fe32-1f59-47eb-a587-1cc114042852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "epochs = 25\n",
    "# Instantiate the WGAN model.\n",
    "wgan = WGAN(\n",
    "    discriminator=discriminator,\n",
    "    generator=generator,\n",
    "    discriminator_extra_steps=5,\n",
    "    batch_size = 100)\n",
    "\n",
    "# Compile the WGAN model.\n",
    "wgan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    "    c_loss_fn = counter_loss,\n",
    "    run_eagerly=True)\n",
    "\n",
    "\n",
    "fit = wgan.fit(train, batch_size=100, epochs=epochs, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a5792-32f0-46dd-ac16-90fa18d1afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.test(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb3277-47f4-4350-b514-aca33acbfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.Series(fit.history['training_loss'])\n",
    "v =  pd.Series(fit.history['val_val_loss'])\n",
    "\n",
    "df = pd.concat([t,v],axis=1)\n",
    "df.rename(columns = {0:\"training\",1:\"validation\"}, inplace=True)\n",
    "df.to_csv(\"losses/WGANGP_100emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f4294-4300-42c8-a553-21bf98ae43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dic=pd.read_csv(\"Eval_dic\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623d46d8-56f5-4cae-a1f7-242ed03f64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dic[\"wgangp_h=64\"] = [wgan.max_g10, wgan.max_g20, wgan.max_m10, wgan.max_m20, wgan.max_p10, wgan.max_p20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601fb2cf-1243-4a1d-bc07-2ba541047d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dic.to_csv(\"Eval_dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abebdeb4-36a4-4c4a-9480-7349df1677f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WGAN-GP_100_epochs_lr_0.0001</th>\n",
       "      <th>GAN_lr.0001_extrastep_1</th>\n",
       "      <th>WGAN-GP_100_epochs_emb100</th>\n",
       "      <th>gan_25embs_sig_after100</th>\n",
       "      <th>gan_emb50_sig_after100</th>\n",
       "      <th>User_Model_GAN_25embs</th>\n",
       "      <th>User_Model_GAN_100embs</th>\n",
       "      <th>User_Model_GAN_50embs</th>\n",
       "      <th>wgangp_h=64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.478360</td>\n",
       "      <td>0.250895</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>0.057132</td>\n",
       "      <td>0.057317</td>\n",
       "      <td>0.057253</td>\n",
       "      <td>0.116934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524330</td>\n",
       "      <td>0.288934</td>\n",
       "      <td>0.107978</td>\n",
       "      <td>0.059718</td>\n",
       "      <td>0.219884</td>\n",
       "      <td>0.063118</td>\n",
       "      <td>0.063212</td>\n",
       "      <td>0.063029</td>\n",
       "      <td>0.131442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.394489</td>\n",
       "      <td>0.200178</td>\n",
       "      <td>0.086576</td>\n",
       "      <td>0.049281</td>\n",
       "      <td>0.172935</td>\n",
       "      <td>0.047454</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>0.097110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421206</td>\n",
       "      <td>0.216806</td>\n",
       "      <td>0.085328</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.048964</td>\n",
       "      <td>0.049055</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>0.099506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350700</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.067667</td>\n",
       "      <td>0.251296</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.075100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.186681</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.078300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WGAN-GP_100_epochs_lr_0.0001  GAN_lr.0001_extrastep_1  \\\n",
       "0                      0.478360                 0.250895   \n",
       "1                      0.524330                 0.288934   \n",
       "2                      0.394489                 0.200178   \n",
       "3                      0.421206                 0.216806   \n",
       "4                      0.350700                 0.179600   \n",
       "5                      0.375900                 0.203800   \n",
       "\n",
       "   WGAN-GP_100_epochs_emb100  gan_25embs_sig_after100  gan_emb50_sig_after100  \\\n",
       "0                   0.100349                 0.047300                0.151600   \n",
       "1                   0.107978                 0.059718                0.219884   \n",
       "2                   0.086576                 0.049281                0.172935   \n",
       "3                   0.085328                 0.050500                0.167600   \n",
       "4                   0.068000                 0.067667                0.251296   \n",
       "5                   0.068600                 0.054700                0.186681   \n",
       "\n",
       "   User_Model_GAN_25embs  User_Model_GAN_100embs  User_Model_GAN_50embs  \\\n",
       "0               0.057132                0.057317               0.057253   \n",
       "1               0.063118                0.063212               0.063029   \n",
       "2               0.047454                0.047565               0.047498   \n",
       "3               0.048964                0.049055               0.048972   \n",
       "4               0.008900                0.008900               0.008900   \n",
       "5               0.005700                0.005700               0.005700   \n",
       "\n",
       "   wgangp_h=64  \n",
       "0     0.116934  \n",
       "1     0.131442  \n",
       "2     0.097110  \n",
       "3     0.099506  \n",
       "4     0.075100  \n",
       "5     0.078300  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c68bef0-73d5-4e82-80e1-f2a05146533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c2ab934-cba2-4911-b210-1bc7bac4890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3KUlEQVR4nO3dd3yV9dn48c+Vk3OyF4QRk0DYsldAFFTEja37caNttWqrtVr72Nr9a58+rbWO9nGV1tZZR11YBw7EQZUREAghsldCFpBF9rh+f5yTcAgJOSEJ5+Sc6/165UXO9/7e9/neHLiv892iqhhjjAk9Yf4ugDHGGP+wAGCMMSHKAoAxxoQoCwDGGBOiLAAYY0yICvd3AboiOTlZMzIy/F0MY4zpU1avXr1PVQe0Te9TASAjI4OsrCx/F8MYY/oUEdnVXro1ARljTIiyAGCMMSHKAoAxxoSoPtUHYIwx/tLQ0EBeXh61tbX+LkqHIiMjSUtLw+l0+pTfAoAxxvggLy+PuLg4MjIyEBF/F+cIqsr+/fvJy8tj2LBhPp1jTUDGGOOD2tpa+vfvH5APfwARoX///l2qoVgAMMYYHwXqw79FV8tnAaATzc3Ky6v2UN/Y7O+iGGNMj7IA0Il1eWXc8+p6Ptlc4u+iGGNC3OLFixkzZgwjR47k97//fbevZwGgEwfrGgE4UFXn55IYY0JZU1MTt912G++++y4bN27khRdeYOPGjd26pgWATlTXNwFQVt3g55IYY0LZypUrGTlyJMOHD8flcnHVVVexaNGibl3ThoF2osYTAEotABhjPP7fv3PYuLeiR6857oR4fvn18R0ez8/PJz09vfV1WloaK1as6NZ7dloDEJF0EVkqIhtFJEdEvt9BvrkistaT55POzhWRX4lIvuectSIyv1t30ksO1QDq/VwSY4zpWb7UABqBu1V1jYjEAatF5ANVbW18EpFE4DHgPFXdLSIDfTz3IVX9Y8/dTs+rrnf3AZRaADDGeBztm3pvSU1NZc+ePa2v8/LySE1N7dY1O60BqGqBqq7x/F4J5AJt3/Ua4DVV3e3JV9yFcwOaNQEZYwLBjBkz2LJlCzt27KC+vp4XX3yRCy+8sFvX7FInsIhkAFOBtg1Po4EkEflYRFaLyPU+nnu7iKwXkb+LSFIH73mziGSJSFZJyfEfilnd4A4A5RYAjDF+FB4eziOPPMK5557L2LFjueKKKxg/vns1EZ87gUUkFngVuFNV2/Z+hAPTgTOBKOALEVmuqpuPcu7jwG8A9fz5APCttu+rqguBhQCZmZnq+631jEM1AGsCMsb41/z585k/v+e6S30KACLixP0Af15VX2snSx6wX1WrgCoR+RSYDGzu6FxVLfK6/l+Bt479NnpPSx9AWXUDqhrwU8GNMcZXvowCEuBJIFdVH+wg2yJgjoiEi0g0cBKQe7RzRSTF6+UlwIZjuYHe1jIKqL6pufV3Y4wJBr7UAGYDC4BsEVnrSfsJMARAVZ9Q1VwRWQysB5qBv6nqBhGZ0965qvoO8AcRmYK7CWgncEuP3FE71ueVsedADRdMSuk8cxs1Xg/9spoGYiJs6oQxoSrQWwFUu9ZK3unTTFWXAZ3esareD9zv67mqusDHMnbbK6vzWLR27zEFAO9v/aVV9aQmRvVk0YwxfURkZCT79+8P2CWhW/YDiIyM9PmckPg6mxjtoqK2gaZmxRHWtQ+upqGJSGcYtQ3NthyEMSEsLS2NvLw8/DEa0VctO4L5KjQCQJQTVaioaSApxtWlc2vqmzghMYrtJVU2EsiYEOZ0On3eaauvCInF4JJi3PtjHssDvLqhkRMS3M0+thyEMSaYhEQASIx2f+svq+l6E05NfRMpCe42NWsCMsYEk9AIAFHuGsCxfIOvrm8iPspJjMthy0EYY4JKSASAJE8NoLSqaw9wVaWmoYlol4PEaJc1ARljgkpIBYCuNgHVNjSjClEuB0kxTusENsYElZAIAHGR4YRJ15uAWpaBiHY6SIp2WROQMSaohEQACAsTEqK6/g2+ZRJYtCucxGgX5cfQiWyMMYEqJAIAuJuBujqKp8azFHSUy0HiMQQQY4wJZCETABKinV0OAIdqAA6Sop2U17hnExtjTDAImQCQFO2irObY+gCiPKOAWmYTG2NMMAiZAJAY7ezyMNAarz6A7swmNsaYQBQ6ASCq6+P4vZuAujOb2BhjAlHIBICkaCdV9U3UNzb7fE5LDSDK6ejWbGJjjAlEIRMAEmNavsH7/gBvnQfgchzzbGJjjAlUoRMAWr/B+/4Ar27w6gNoCQBWAzDGBImQ2A8AvJaD6EIAqKlvQgQinWFEhId5ZhNbDcAYExxCJgAkRnd9FE91fRNRTgcigoh7WemuDiU1xphA1WkTkIiki8hSEdkoIjki8v0O8s0VkbWePJ94pZ8nIptEZKuI/NgrfZiIrPCkvyQiXduqq4taAkBXOnGr690rgbZeI8pp6wEZY4KGL30AjcDdqjoOmAXcJiLjvDOISCLwGHChqo4H/suT7gAeBc4HxgFXe517H/CQqo4ESoEbu387HTuWJqDahiaivANAtNNGARljgkanAUBVC1R1jef3SiAXSG2T7RrgNVXd7clX7EmfCWxV1e2qWg+8CFwkIgLMA17x5HsauLib93JU0S4HLkdYl77BV9c3Eu081EqWFO2yUUDGmKDRpVFAIpIBTAVWtDk0GkgSkY9FZLWIXO9JTwX2eOXL86T1B8pUtbFNenvvebOIZIlIVklJSVeK2/Y6nvWAutgHcFgNwFYENcYED587gUUkFngVuFNVK9q5znTgTCAK+EJElvdEAVV1IbAQIDMzs1srsSV1cUG4mjZ9AEnRtiKoMSZ4+BQARMSJ++H/vKq+1k6WPGC/qlYBVSLyKTDZk57ulS8NyAf2A4kiEu6pBbSk96rEKFeXRwG1dB6Duw+gur6JusYmIsIdRznTGGMCny+jgAR4EshV1Qc7yLYImCMi4SISDZyEu69gFTDKM+LHBVwFvKmqCiwFLvecf4PnGr0q0bOks69qGpqIch2KkYnH0JFsjDGBypc+gNnAAmCeZ5jnWhGZLyK3isitAKqaCywG1gMrgb+p6gbPt/vbgfdwB4SXVTXHc90fAT8Qka24+wSe7NE7a4d7W8euLQUR5Tz0V2SzgY0xwaTTJiBVXQaID/nuB+5vJ/0d4J120rfjHiV03CRGu8fxqyruis3RuecBeI8C6vpyEsYYE6hCZi0gcDfh1Dc2U9vg24qgNe2MAgJbEdQYExxCKgAkdWE5iPrGZhqblWjnoQCQHOcOAIXltb1TQGOMOY5CKgB0ZT2g1r0AvGoAA2IjiHSGsae0pncKaIwxx1GIBQD3N/hyH9rwqxta9gI41AcgIgzpF82eA9W9U0BjjDmOQioAHBrF40MA8NoO0lt6UjS7LQAYY4JASAWA7jYBAaR7agDuqQzGGNN3hWQA8GUyWEc1gCH9oqmqb7JloY0xfV5IBYCIcAfRLgelVZ3XALz3A/aW3i8awJqBjDF9XkgFAPB9U5fWJiDn4XPlhlgAMMYEidALANEuyn3Y1rHDTuB+UQA2EsgY0+eFXABIivGtBlDd0H4AiHaFkxzrsgBgjOnzQi4A+LokdI2nD6DtKCBw9wNYE5Axpq8LvQAQ7fRpIlhNvXu9IO+JYC2G9ItmT6kFAGNM3xZyASA5NoLS6nryOnmAVzc04goPwxF25Kqh6UnR7C2rpaHJt0XljDEmEIVcALhiRjqRTge/WJRz1MlcbbeD9DakXzRNzUpBmS0KZ4zpu0IuAKQmRvGDs0fz0VfFLN5Q2GG+6vqmw1YC9dYyF8CagYwxfVnIBQCAb5ySwbiUeH717xwqa9vvD2i7F4C3lqGg1hFsjOnLQjIAhDvC+N9LJ1JcWccD729uN091fWO7HcAAKQlRhIeJBQBjTJ8WkgEAYEp6ItfPGsrTX+xkc1HlEcerj1IDcIQJaUlRNhfAGNOnhWwAALjzrNHEuMJ56IMjawE1DR13AsOhVUGNMaav6jQAiEi6iCwVkY0ikiMi328nz1wRKReRtZ6fX3jSx3ilrRWRChG503PsVyKS73Vsfo/fXSeSYlzcOGcY724oZEN++WHHqo8yCghsMpgxpu/zpQbQCNytquOAWcBtIjKunXyfqeoUz8+vAVR1U0saMB2oBl73Ouchr3Pe6d6tHJsbTx1GQpSTB97fdFh6TX0TkR2MAgL3XIDS6oYOO5GNMSbQdRoAVLVAVdd4fq8EcoHUY3ivM4FtqrrrGM7tNfGRTm45fThLN5WweteB1nR3J3DHAaBlVdA9Bw7fH7i4spbzHv6Uv366vXcKbIwxPaRLfQAikgFMBVa0c/hkEVknIu+KyPh2jl8FvNAm7XYRWS8ifxeRpA7e82YRyRKRrJKSkq4U12ffOCWD5FjXYSOC3E1A7Y8CgvaXhS6vaeD6J1fyVWElH+QW9UpZjTGmp/gcAEQkFngVuFNVK9ocXgMMVdXJwP8Bb7Q51wVcCPzLK/lxYAQwBSgAHmjvfVV1oapmqmrmgAEDfC1ul0S7wvnu3JF8vm0/K3ccoKlZqWtsJuooTUBDk6OJdIbx80UbePrznZTXNHDT06vYVnKQyemJbNxbQXOzbRtpjAlcPgUAEXHifvg/r6qvtT2uqhWqetDz+zuAU0SSvbKcD6xR1SKvc4pUtUlVm4G/AjO7cR/ddvXMIfSLcfGXT7ZR08FS0N7iI508f9MshiXH8Ms3c5jx2w/J2lXKw1dO5dqZQzhY18iO/VXHq/jGGNNlvowCEuBJIFdVH+wgz2BPPkRkpue6+72yXE2b5h8RSfF6eQmwoWtF71lRLgc3nJzBkq+KWb+nDDh6AACYPjSJl26exbM3zuSkYf24//LJXDAphQmpCQBHjCwyxphA0nEj9yGzgQVAtois9aT9BBgCoKpPAJcD3xGRRqAGuEo9K62JSAxwNnBLm+v+QUSmAArsbOf4cXf9yUN54pNtPPzhFgCijtIH0EJEOHXUAE4ddah5atSgWFzhYWTnlXPRlGPpLzfGmN7X6RNOVZcBR66JfHieR4BHOjhWBfRvJ32Bj2U8bpJiXFw5I52nPt8JdF4D6IjTEcbYlHiyrQZgjAlgIT0TuD03zhnWugdAR0tB+GJiajw51hFsjAlgFgDaSO8XzdcnubsnOloO2hcTUxM4WNfITusINsYEKF/6AELOHWeOoriyjtGD4o75Gi0dwdn55QwfENtTRTPGmB5jNYB2DB8Qyz+/PYukGNcxX2P0oDhc4WE2EsgYE7AsAPQS6wg2xgQ6CwC9aGJqPBvyrSPYGBOYLAD0IusINsYEMgsAvci7I9gYYwKNBYBeZB3BxphAZgGgFzkdYYwdHGc1AGMCWHFFLZN+9V5IflGzANDLJqQmkGMdwcYErJ37q6mobSS3oO0q98HPAkAvm5iaQGVdI7ts/2BjAlLLtq7lNaG3vasFgF5mHcHGBLYKTwAoq7YAYHrY6EFxuBzWEWxMoKqsbQSgtLrezyU5/iwA9DJXeBgnpsSRnWcBwJhA1BIAyqwJyPSGCakJbNhbjmePHGNMADnUBGQ1ANMLJqYmUFnbyK791hFsTKCpqPHUAKwPwPSGidYRbEzAqrROYNObWjqCLQAYE3ha+wCsCehIIpIuIktFZKOI5IjI99vJM1dEykVkrefnF17HdopItic9yyu9n4h8ICJbPH8m9dxtBRbrCDYmcLX0AVTVN1Hf2Ozn0hxfvtQAGoG7VXUcMAu4TUTGtZPvM1Wd4vn5dZtjZ3jSM73SfgwsUdVRwBLP66BlHcHGBKaWGgBAWU1g1gJy9vbOl8dOA4CqFqjqGs/vlUAukNoD730R8LTn96eBi3vgmgHLOoKNCUyVtQ3EuNz7f5cHYD/A0k3FXPDnZbyTXdDj1+5SH4CIZABTgRXtHD5ZRNaJyLsiMt4rXYH3RWS1iNzslT5IVVvuqBAY1MF73iwiWSKSVVJS0pXiBhTrCDYmMFXUNJLeLxoIvLkAVXWN/Oz1DYwcGMuZYwf2+PV9DgAiEgu8Ctypqm1XTVoDDFXVycD/AW94HZujqtOA83E3H53W9trqbhdpt21EVReqaqaqZg4YMMDX4gYcmxFsTOBpaGqmpqGpNQCUVgVWE9AD728mv6yG3186kYhwR49f36cAICJO3A//51X1tbbHVbVCVQ96fn8HcIpIsud1vufPYuB1YKbntCIRSfFcPwUo7ua9BDRXeBjjTojnrfUFFFXU+rs4xhjgoKf9f0gA1ACydh5g/p8+45kvdlLX2MTaPWU89fkOFswaSmZGv155T19GAQnwJJCrqg92kGewJx8iMtNz3f0iEiMicZ70GOAcYIPntDeBGzy/3wAs6s6N9AW//Po4Sqvrue5vKzgQYN80jAlFLR3A6UlRgH+Hgt7/3iY2FVXyi0U5zPvjJ9z54pcMjIvknvPG9Np7+lIDmA0sAOZ5DfOcLyK3isitnjyXAxtEZB3wZ+AqT7POIGCZJ30l8LaqLvac83vgbBHZApzleR3Upg5J4m83ZLL7QDU3/H1l6/AzY4x/tPwfTEmMIjxM/DYZbPWuUlbsOMC955/IszfOJDkugp37q/nNxROIi3T22vuGd5ZBVZcB0kmeR4BH2knfDkzu4Jz9wJm+FTN4nDIimcevm8bNz6zm7pfX8dfrMzs/yRjTK1oCQHykk8Rop9+agJ74ZBuJ0U6unjmEmIhw5oxMpqSyjoHxkb36vjYT2A/mnTiIm04dzkdfFYfk7ENjAkVLE1BcZDgJUU6//H/cUlTJBxuLuOHkDGIi3N/JRaTXH/5gAcBvzhk/iKZm5ZPNfXdoqzF9XUXNoRpAUrTLL01AT3yynSingxtOyTju720BwE+mpCXSP8bFktygHvxkTEBrqQHER4WTGO2k9DgHgLzSahatzeeqmen0i3Ed1/cGCwB+ExYmnHHiQD7eVExDU2itP2JMoGgJALER4SREuSg/jk1Ay7fv58q/LCcsTLjp1OHH7X29ddoJbHrPmScO5JXVeazeVcqs4f39XRxjQk5FbQPRLgfhjjCSeqkTWFW597Vs3t1QyMnD+zNnVDJ7SqtZ+Ol2hvaL5uVbTiY1MarH39cXFgD86NTRA3A6hCW5RRYAjPGDytoG4j3DLBOjnVTXN1HX2NSjs24f+nALL67aw5yRyWTnl7M4pxCAq2cO4WcXjG3t+PUHCwB+FBsRzqzh/VnyVTE/vaC9BVaNMb2psraRuEj3YzAx2t0GX17dwMD4ngkAL6/aw5+XbOGKzDTuu2wSANv3VVFT38QEz/pg/mR9AH525okD2V5SxY59Vf4uijEh5/AA4K4J9FRH8GdbSrj39WxOHZXMby+ZiIggIowYEBsQD3+wAOB3Z451L4K6JLfIzyUxJvRU1DYQH+VpAopy1wB6Yi5Ac7PyyzdzyOgfzWPXTsPpCMxHbWCWKoSk94tm9KBYGw5qjB+4awCH+gCgZxaE+2RzCdtLqvjevFG9upRDd1kACACnjhrAmt2lNhzUmOOssrbhiCagnqgBPLlsB4PjI5k/MaXb1+pNFgACwKS0BOoam9lSdNDfRTEmpFTUHOoDSIpuaQLqXg3gq8IKlm3dx/WnDMUVHtiP2MAuXYho2S3MNosx5vipbWiivqm5dRhotMuB0yHd7gT++7IdRDkdXDNzSE8Us1dZAAgAGf1jiIsIZ31+mb+LYkzIaF0GIvLQAmwJUS7Ku7AxfFOzcuuzq7l64XI+3FhEcWUtb6zdy2XTU1uHlQYymwcQAMLChPGp8WTnWQ3AmOOlZSlo707apGhnl5qA/vLpNhbnFNI/xsVNz2QRFxFOfWMz35o9rMfL2xusBhAgJqUlkltYSX2jdQQbczx4LwTXwr0gnG81gPV5ZTz4/mYumJjC8p+cyZ+vnsqIgbFcNSOd4QNie6XMPc1qAAFiYmoC9Y3NbC6qDJhJIsYEs8p2agAJUS7ySqs7Pbe6vpE7X1zLgLgIfnvJBJyOMC6cfAIXTj6h18rbG6wGECBaOoKzrSPYmOPCezOYFr42Af327Vx27K/igSsm94m2/o5YAAgQQ/tHExcZbgHAmOOkZTMY7xqAe1vIozcBrd51gOdX7ObG2cM4ZURyr5axt1kACBAiwqS0BOsINuY4aTsKCNwLwtU2NFPb0NTuOY1Nzfz8jRxSEiK56+zRx6WcvanTACAi6SKyVEQ2ikiOiHy/nTxzRaRcRNZ6fn7R2bki8isRyfc6Z37P3lrfMyE1ga8KK6hrbP8fnzGm51TWNiACMa7DO4Gh48lgz6/YzcaCCn7+tXF+Xca5p/hyB43A3aq6RkTigNUi8oGqbmyT7zNV/VoXz31IVf/YvVsIHpNSE2loUjYXHmRimnUEG9ObKmobiY0IJyxMWtNaF4SrqWdwwuGbspdU1vHH9zdx6qhkzp8w+LiWtbd0GgBUtQAo8PxeKSK5QCrQNgD06LmhaJLnob8+v8wCgDG9rMJrM5gWSS1LQlc1UFHbwJLcIg5UNdDU3MxnW/ZR29DEry4cj4i0d8k+p0t1GBHJAKYCK9o5fLKIrAP2Aj9U1Rwfzr1dRK4HsnDXFErbec+bgZsBhgwJ/KnV3ZGWFEVClNPdD3CSv0tjTHDz3gugRYInAPzu3Vw2FVZS12Zezn+fO4YRfWSMvy98DgAiEgu8CtypqhVtDq8BhqrqQU9b/hvAqE7OfRz4DaCePx8AvtX2fVV1IbAQIDMzU30tb1/U2hFsI4GM6XUVNUfWAAbHR+J0CDv3VXFFZjqXTktleHIs4Q4h3CE9ulVkIPApAIiIE/cD/HlVfa3tce+AoKrviMhjIpKsqvs6OldVW3dAEZG/Am914z6CRubQfjy8ZDObCisZMzjO38UxJmhV1jZyQuLh7fz9YyNY+sO5JMdGEOkMrod9e3wZBSTAk0Cuqj7YQZ7BnnyIyEzPdfcf7VwR8V4o+xJgw7HdQnC54ZShxEWE8/t3c/1dFGOCWmVdQ7ubtaQlRYfEwx98mwcwG1gAzPMesikit4rIrZ48lwMbPH0AfwauUlXt6FzPOX8QkWwRWQ+cAdzVo3fWRyVGu7jtjJEs3VTC51v3+bs4xgSt9voAQo0vo4CWAUft8lbVR4BHunKuqi7wsYwh54ZTMnjmi1387t2vWHTb7MOGqRljuk9VLQBgM4EDUqTTwQ/PHU12fjn/Xr/X38UxJuhU1zfR1KxHdAKHGgsAAeqiyamMS4nnD4s32RLRxvSwQwvBWQAwASgsTLjnvDHkl9Xwxpf5/i6OMUHl0GYwod0EFNp3H+BOHz2ACanxPP7JNi6bnobD+gKMOWYH6xp5ceVuSqvr2X2gBoD4qNCuAVgACGAiwm1zR/Kd59fwdnZBn9tswphAoar86NX1vL2+AEeYEO1yMCw5htGDgmdW77GwABDgzh0/mBEDYnhs6Va+PiklaNYgMeZ4ev3LfN5eX8B/nzuG784dYf+PPKwPIMCFhQnfnTuSrworWZJb7O/iGNPn7DlQzS8W5TAzox+3nm4Pf28WAPqAC6ecQFpSFI8s3Yp7fp0xxheNTc3c9dJaBHjwysnWj9aGBYA+wOkI41uzh7F2Txm79ne+YbUxxu3hD7eQtauU31w8gbSkaH8XJ+BYAOgjpg9NAuCrwko/l8SYvuGd7AIeWbqVKzPTuWiKDaBojwWAPmLUoFhEYJMFAGM6lVtQwd0vr2PakER+fXHwbODS0ywA9BHRrnCG9Itmc5EFAGOO5kBVPd9+Jov4qHCeuG560K3h35NsGGgfMnpQHF8Vtt2LxxjTYs+Bar751CqKK+t4+ZaTGRgf2flJIcxqAH3IiYPj2Lm/mtqGJn8XxZiA8+XuUi557D8UV9Ty1DdnMCU90d9FCngWAPqQ0YPiaGpWtpUc9HdRjAkYqspra/K4auFyolwOXvvubE4ZkezvYvUJ1gTUh5zo2SJyc1El409I8HNpjPG/fQfr+NnrG1icU8iMjCQev246ybER/i5Wn2EBoA/JSI7B6RAbCmpCUn5ZDS+t2sO2koNEhIfhcoTxwcYiKmsb+fH5J/LtU4fbRK8usgDQhzgdYYwYEMtmCwAmhKzZXcqjH21l6aZiFBjaL5qGJqW+qZnhA2L4n4snMsZTOzZdYwGgjxkzOI5VOw74uxjGHBdFFbXc8PeVRIQ7+O7ckVw1M91m9PagTjuBRSRdRJaKyEYRyRGR77eTZ66IlHtt/P4Lr2PnicgmEdkqIj/2Sh8mIis86S+JiKvnbit4jRkcx97y2tYNLYwJZr9clENdYzP/uvVkfnjuGHv49zBfRgE1Aner6jhgFnCbiIxrJ99nqjrF8/NrABFxAI8C5wPjgKu9zr0PeEhVRwKlwI3dvJeQMGaQu6q7xSaEmSD3Xk4hi3MKufOsUQxLjvF3cYJSpwFAVQtUdY3n90ogF0j18fozga2qul1V64EXgYvEPS97HvCKJ9/TwMVdLHtIamnrtI5gE0wam5q58JFlXPb45yzeUEh5dQO/WLSBsSnxfPvU4f4uXtDqUh+AiGQAU4EV7Rw+WUTWAXuBH6pqDu5AsccrTx5wEtAfKFPVRq/0doOKiNwM3AwwZMiQrhQ3KKUmRhEbEW4dwaZPUdWjrsfzwcYi1ueV0y/Gxa3PrSbG5aCmoYmFCzJxOmy6Um/x+W9WRGKBV4E7VbXtegRrgKGqOhn4P+CNniqgqi5U1UxVzRwwYEBPXbbPEhFGD4q1GoDpM/LLapj1uyX8c8XuDvP84z87SUuKYvm9Z/LoNdMYn5rAD84ezWSbzdurfKoBiIgT98P/eVV9re1x74Cgqu+IyGMikgzkA+leWdM8afuBRBEJ99QCWtKND8YMjmPxhsJOv1UZEwjeXLuXooo6fr5oA+n9ojh11OFf5Dbkl7Ny5wF+On8srvAwLpiUwgWTUvxU2tDiyyggAZ4EclX1wQ7yDPbkQ0Rmeq67H1gFjPKM+HEBVwFvqntbq6XA5Z5L3AAs6u7NhIoxg+IorW5gQ74tDGcC39vZexmXEs+ogbF89/k1bC0+vPb61Oc7iXY5uGJGegdXML3Flyag2cACYJ7XMM/5InKriNzqyXM5sMHTB/Bn4Cp1awRuB97D3Xn8sqdvAOBHwA9EZCvuPoEne/C+gtq8EweRFO3kssc/55GPttDQ1AxAaVU96/aU0dxs20aawLBzXxUb8iu4dFoqf7shk4jwML71VBb5ZTWAeymHN9fu5bJpaSREOf1c2tAjfWmP2czMTM3KyvJ3MQLCvoN1/PLNHN5eX8Cw5BjqG5tb/1M9dOVkLpma5ucSGgOPLt3K/e9t4j8/nkdqYhRrdpdyzV+X09wMV8xIIzwsjKc+38mHPzidkQNj/V3coCUiq1U1s226da/3UcmxETx6zTSeuG4a/WNcTBuaxL3nn0hKQiRvrSvwd/GMAeDt9QVMHZJIamIUANOGJPHBXadzeWYaL63aw1Of7+S00QPs4e8nthREH3fehBTOm3Cow6y4so5nv9hFZW0DcZFWpTb+s2NfFRsLKvjZBWMPS0/vF83/XjKR288YyYsrd/O1ybZfr79YDSDInD9hMPVNzXz0VbG/i2JC3DvZ7pro/Intj+g5ITGKH5wzhtGDbCE3f7EAEGSmDUliYFwEizcUHpZeXFHb2llszPHw1voCpg9N4gRP848JPBYAgkxYmHDu+MF8vKmEmnr31pE5e8uZc99S/r5sh59LZ0LFktwicgsquKCDb/8mMFgACELnTxhMTUMTn2wuprahibteWkt9UzOrdtoy0qZ3qSp/+2w7334mi7Ep8Vw2zUajBTLrBA5CM4f1IynayTvZhazaWcrmooOMGBDD2j3lNnvY9Jr6xmZ+9kY2L2flcd74wTxwxWRiIuwRE8js0wlC4Y4wzhk3mNfX5lPf2Mz1Jw9lxIBYfvlmDgXltdYma3qcqvLT17P51+o87pg3kjvPGk2Ybc8Y8KwJKEidN3Ew9Y3uLfPuPX9s66Ja6/aU+bVcpm9atfMAP309m3ezCzhY13jE8YWfbm99+P/gnDH28O8jrAYQpOaMTGbBrKFcc9IQolwOxqbE4XQI6/LKOd865kwXlNc0cPs/11BUUcfzK3bjcoQxa0R/vjYxhXPHD2b5jv38fvFXXDAphTvPGu3v4pousAAQpJyOMH5z8YTW1xHhDk4cHM/6vDL/Fcr0Sf/7di4llXW8+p1TaGhqZkluEYtzCrnn1fX89I1sRIRJqQk88F+T7Zt/H2MBIIRMTk9g0Zd7aW5W+49qfPLp5hJeytrDraePYPrQJABmDe/PT+aPZX1eOW+t38vmooPcf/kkIp0OP5fWdJUFgBAyKS2R55bvZvu+Klt7xXTqYF0j976WzfABMdx51qjDjokIk9MTbcOWPs46gUPIFOsIDilNzcoLK3ezc19Vl8/dtb+Km55exd7yGvt2H8QsAISQEQNiiXY5rB8gBJRV1/ONf6zk3tey+fmiDT6f19DUzKNLt3LOQ5+yIb+C+y6bxPSh/XqxpMafrAkohDjChAmpCazLK/d3UUwv2lRYyc3PZrG3rIY5I5P5bMs+NhdVdrroWn1jM996ahXLtu7j/AmD+eXXxzM4IfI4ldr4g9UAQsyU9EQ27q2gvtEWhgtGxZW1XP7E51TXN/HizbP489VTiQgP4x//2XnU81SVn72RzbKt+/jdpRN5/Lrp9vAPARYAQsyktATqm5rZVFjZeWbT5zy2dFvrw3/60H70i3FxydRUXluTR2lVfWu+TYWVfL5tX+sXgcc+3sbLWXncceYorp45xF/FN8eZNQGFmMlpiQCszStjYlqCfwtjelR+WQ3/XLGb/5qexogBh0Z5fXP2MF5ctYd/rtzNbWeM5N/r9nLXS2tpbFbiIsKZnpHEx5tKuGjKCdzVZrSPCW5WAwgxaUlRDIiLYPm2/f4uiulhj3y0BYDvnXn4Q3zM4DjmjEzm2S928ezyXdzx4pdMG5LEE9dN42uTU8gtqOCUEf35w+WTbKHAENNpDUBE0oFngEGAAgtV9U8d5J0BfAFcpaqviMgZwENeWU70HHtDRJ4CTgdaeiS/oaprj/VGjG9EhLPGDuLNtfnUNjTZ8L4gsXNfFS9n5bFg1tDW/Xe9fWtOBt96Koufv7GBuWMG8Pi104lyOQ7bTtSEHl9qAI3A3ao6DpgF3CYi49pmEhEHcB/wfkuaqi5V1SmqOgWYB1R7Hwf+u+W4PfyPn3PHD6Kqvon/bN3n76KYHvLwh5txOoTvnjGi3eNzRw9k5rB+XDotlYULMolyWeA3PtQAVLUAKPD8XikiuUAqsLFN1u8BrwIzOrjU5cC7qlp97MU1PeGUEcnERYTzXk4hZ44d5O/imG7aWlzJonV7ufm04QyMa3/kTliY8PItJx/nkplA16U+ABHJAKYCK9qkpwKXAI8f5fSrgBfapP1WRNaLyEMiEtHBe94sIlkiklVSUtKV4poOuMLDOOPEgXyYW0yj7RPc5z22dBuR4Q5uOa39b//GdMTnACAisbi/4d+pqhVtDj8M/EhV232aiEgKMBF4zyv5Xtx9AjOAfsCP2jtXVReqaqaqZg4YMMDX4ppOnDt+MAeq6snaVervophu2LW/ikXr9nLdrCH0i3H5uzimj/EpAIiIE/fD/3lVfa2dLJnAiyKyE3dTz2MicrHX8SuA11W1oSVBVQvUrQ74BzDz2G7BHIu5YwbgCg/jvZxCfxfFtENVfcr3xCfbcIQJ3z51eC+XyASjTgOAuMeFPQnkquqD7eVR1WGqmqGqGcArwHdV9Q2vLFfTpvnHUytouf7FgO8Llphui4kI59SRybyfU+Tzw8YcH+9mFzDtNx9QXFF71Hx7y2p4ZXUeV81IZ2C8zdo1XedLDWA2sACYJyJrPT/zReRWEbm1s5M9/QbpwCdtDj0vItlANpAM/E/Xim6669wJg8kvqyHHszTEtpKDVNY2HJGvtqGJinbSQ9XrX+b16kzq93IKKa1u4Nnlu46ab+Gn21GFW063tn9zbHwZBbQM8Hl2iKp+o83rnbhHDbXNN8/Xa5recdbYQYQJXP3X5VTVNdKsMCMjiZdvOfmwCUHfe+FLthUf5MMfnB7yG8ms3VPGXS+tIyI8jN9cNIErZqT36PVVleXbDwDw3PJd3HbGyMPmahRV1LJq5wGydpbywsrdXDYtrd1x/8b4wpaCCGH9YlzcedZothYfJCM5hgNVdTy3fDf/2bqfOaOSAffeAR9sLALcG4OfNLy/P4vsd08u20FcRDgT0xK459X1rNp5gF9fNKHHxtXvPlBNYUUtX598Av9et5fX1uRzzUnutXneWr+XO174kmaFSGcYM4f1486zbekGc+wsAIS4O7yWDahrbOLDjcX8aclmZo/sj4jw5yVbSIhy0tjUzKtr8o5LAHj9yzympieRkRzT6+/VFXvLangnu4BvnpLBvfPH8qcPN/Pnj7aSs7eCvyyYTnq/6G6/x/Lt7iU67pg3kh37DvLksu1cNSOdbSUHueeV9UwdksQvvz6OsSnxOB22kovpHvsXZFpFhDv4ztwRrNpZyhfb95OdV86Sr4q5ac4wzp+YwjvZhdTUN/VqGfYcqOaul9bxk9eze/V9WjQ2NbNi+36amzvvCH/mi12oKjeckoEjTPjBOWP4xzdmkFdazdcfWcanm7s/T2XF9gP0j3ExcmAsN80ZzraSKt7OLuCW51YT7QrnsWunMSkt0R7+pkfYvyJzmCtnpDMwLoI/fbiFP3m+/d8wO4PLpqVxsK6R9zf27rDRd7ILAPh8235W+zhH4V9Ze3jg/U3HNJrpT0u2cOXC5Tz+ybbD0tftKWP27z/isY+3oqpU1zfywsrdnDt+8GHf9M84cSBv3j6HwfGR3PCPlbyyOq/LZWihqqzYcYCThvdDRJg/MYVB8RHc+dJadu2v5pFrpjLIRvuYHmQBwBwm0ung1tNHsGLHAT7MLeLGOcOIj3Ry0rB+pCZG8eqa/Na8dY1NFJYffahiV721voATB8fRL8bFo0u3dpq/ur6R37y1kf/7aCt/72TTk7Z27KviL59sJy4inAfe39S6NlJ+WQ03PZPFvoN1/GHxJr7z3Bqe/nwX5TUN3Dhn2BHXyUiO4bXvnsKU9EQefH8TTT7UJtqTV1pDflkNszzNbK7wMG44JYOmZuVH541pTTemp1gAMEe45qQhJMdGEB8ZzjdmZwDutWQunZbKsi0lFFXUsnNfFRc98h9Ou38pm4t6Zkjkrv1VZOeXc+m0VL41O4OPvipmQ/7Rt69ctHYvFbWNjEuJ53/fyWXFdt+WuVZVfrFoAxHhYbx1xxyGD4jl+y9+ybaSg9z41Cpq65v49/fm8LMLxvJBbhH3Lf6KyWkJTB+a1O71ol3h3DRnOHvLa/l0y+FNQb9YtIFv/mMlVXWNRy1TS/v/ScMOPehvPnU4/7r1ZJvoZXqFBQBzhEing78smM7C6zOJj3S2pl8yNZVmdT/Qvv7IMgoraol2Ofjvf63rkTWF3lrvbv65YNIJXH9KBnGR4UetBagqT3++k7Ep8bx4yyyG9ovmtn9+SVEnE6gA3t1QyGdb9nH3OaMZ2j+GJ66bRnV9E+c//Blbig/y6LXTGD0ojptOHc5zN57EmEFx3HX26KOul3/2uEH0j3Hx4srdrWk5e8t55otdLN1Uwo1PrzpqH8qKHQdIinYyauChzVzCHWHMyOhn6/SbXmEBwLRr+tCkI5ochg+IZdqQRN7LKSKjfwz/vn0O/3PxBNbllfO3ZTvavU5VXSOvrs7jg41FbCqspLq+42/Bb60vYNqQRFITo4iPdPKNUzJYnFPIlg5qGKt2lvJVYSU3nDyU+EgnTyyYTlVdI1/7v2X81xOf8+1nslj46bYjzquqa+TX/97IuJR4rps1FICRA+P43aUTaVbl1xeN57TRh9adOnlEf9676zTmjhl41L8zV3gYl01PY0luMcWV7iD08IdbiIsM5zcXjWfFjgPc/GwWtQ3tB4Hl2/dz0rD+IT/Xwhw/NgzUdMlPLxjH51v38e3ThhPpdJCWFMVb4wt48IPNnDV2ICMHxrXm3Vp8kO88t5otxQdb08IEzhgzkOtmDeW00QNweB5220oOkltQwc+/dmiriW/OHsaTy3Zw+z+/5PHrpjHca5tDgKe/2El8ZDgXTXHPMxw9KI6/Xp/Jc8t3UVZTz9big3ywsYhxKQmt8xoAHvt4K4UVtTx67TTCvUbTXDQllbPHDSLadez/La6ckc7CT7fzyuo85oxM5oONRfzg7NEsODmDiHAH97y6nnl//BhneBjV9U0kRTu5IjOdU0Ykk1da024fgzG9RfrSOjCZmZmalZXl72KYNkoq6zj7oU9ISYhiwayhjBkcR15pNT95LZsIp4P7L59E/9gI9hyoJmdvBa+szmPfwTrSktz5r5yRzjNf7OKhDzfzxY/PZHDCoZEun20p4Y4XvqShSbnvsklcMMm9g1VheS1z7vuIb87O4KcXHLE/EeDupJ73x0/oF+PizdtnIyLklVYz74FPuGBiCg9dOaVX/j6u+MsXFFXUktE/hnV5ZXx2zxnEeZrSFq3N5+31BUS5HES7HGwuOsjqXaWIgCq8c8epjDshvlfKZUKXiKxW1cwj0i0AmJ7wXk4hP/zXOiprDzXxTB2SyGPXTiMl4fClCuobm3l/YyHPfrGLFTsOEOkMIyLcwZhBcbx865Gbluwtq+G2f67hy91lTBuSyAmJUew/WM/yHfv5+IdzGdq/4wljr6zO44f/Wsdj105j/sQU7njhS97LKWTpD+dyQi8tofD6l3nc9dI6AH503ol8Z+7R1+rJ2VvOc8t3caCqnsevnW5NQKbHWQAwvU5VySut4avCSipqGvj65BNwhR+9mym3oIKnP9/JorV7+e0lE7h0Wlq7+eobm3nkoy2s2HGA4so6iipqOWfcIB6+aupRr9/UrJz38Kc0NSt/uHwSlz/xBd+bN5K7zxlzzPfZmdqGJmb+9kOcjjA+vecMYiKspdX4lwUAE7LeyynklmdXEx8ZToTTwcc/nNvrD+WPNxUT6XTY2H0TEDoKAPbVxAS9c8YNYkp6Imv3lHHfBWOPyzfyzkYMGRMILACYoCci3H/5JN7OLuDy6T27fLMxfZkFABMSRg2K485BcZ1nNCaE2EQwY4wJURYAjDEmRFkAMMaYENVpABCRdBFZKiIbRSRHRL5/lLwzRKRRRC73Smvy2kz+Ta/0YSKyQkS2ishLIuLq/u0YY4zxlS81gEbgblUdB8wCbhORI+bei4gDuA94v82hGlWd4vm50Cv9PuAhVR0JlAI3HtMdGGOMOSadBgBVLVDVNZ7fK4FcILWdrN8DXgWKO7umuNe2nQe84kl6GrjYtyIbY4zpCV3qAxCRDGAqsKJNeipwCfB4O6dFikiWiCwXkYs9af2BMlVtWTgmj/aDCiJys+f8rJKS7u+5aowxxs3neQAiEov7G/6dqlrR5vDDwI9UtbmdjSuGqmq+iAwHPhKRbODo2zx5UdWFwEJwLwXh63nGGGOOzqcAICJO3A//51X1tXayZAIveh7+ycB8EWlU1TdUNR9AVbeLyMe4axCvAokiEu6pBaQB+e1c9zCrV6/eJyK7fClzO5KBfcd4bl8WivcdivcMoXnfoXjP0PX7HtpeYqcBwNNe/ySQq6oPtpdHVYd55X8KeEtV3xCRJKBaVetEJBmYDfxBVVVElgKXAy8CNwCLOiuLqg7oLM9R7iOrvcWQgl0o3nco3jOE5n2H4j1Dz923LzWA2cACIFtE1nrSfgIMAVDVJ45y7ljgLyLSjLu/4fequtFz7Ee4aw3/A3yJO8gYY4w5TjoNAKq6DPB5hwpV/YbX758DEzvItx2Y6et1jTHG9KxQmgm80N8F8JNQvO9QvGcIzfsOxXuGHrrvPrUhjDHGmJ4TSjUAY4wxXiwAGGNMiAqJACAi54nIJs/Ccz/2d3l6Q0eL9olIPxH5QES2eP5M8ndZe5qIOETkSxF5y/M66BcaFJFEEXlFRL4SkVwROTnYP2sRucvzb3uDiLwgIpHB+FmLyN9FpFhENniltfvZitufPfe/XkSmdeW9gj4AeBapexQ4HxgHXN3eYnZBoKNF+34MLFHVUcASz+tg833ca1S1CIWFBv8ELFbVE4HJuO8/aD9rz3IzdwCZqjoBcABXEZyf9VPAeW3SOvpszwdGeX5upv3leDoU9AEA91DTraq6XVXrcU88u8jPZepxR1m07yLci+1BEC66JyJpwAXA3zyvg36hQRFJAE7DM3dGVetVtYwg/6xxD1uPEpFwIBooIAg/a1X9FDjQJrmjz/Yi4Bl1W457hYUUX98rFAJAKrDH63WHC88FizaL9g1S1QLPoUJgkL/K1UseBu4Bmj2vfV5osA8bBpQA//A0ff1NRGII4s/as6TMH4HduB/85cBqgv+zbtHRZ9ut51soBICQcrRF+9Q95jdoxv2KyNeAYlVd7e+yHGfhwDTgcVWdClTRprknCD/rJNzfdocBJwAxHNlMEhJ68rMNhQCQD6R7vfZp4bm+qINF+4paqoSePzvdr6EPmQ1cKCI7cTftzcPdNp7oaSaA4Py884A8VW1Zlv0V3AEhmD/rs4Adqlqiqg3Aa7g//2D/rFt09Nl26/kWCgFgFTDKM1rAhbvj6M1OzulzjrJo35u4F9sDHxfd6ytU9V5VTVPVDNyf60eqei3QstAgBNk9A6hqIbBHRMZ4ks4ENhLEnzXupp9ZIhLt+bfecs9B/Vl76eizfRO43jMaaBZQ7tVU1DlVDfofYD6wGdgG/NTf5emle5yDu1q4Hljr+ZmPu018CbAF+BDo5++y9tL9z8W9Ci3AcGAlsBX4FxDh7/L1wv1OAbI8n/cbQFKwf9bA/wO+AjYAzwIRwfhZAy/g7udowF3bu7Gjzxb3Om2Pep5t2bhHSfn8XrYUhDHGhKhQaAIyxhjTDgsAxhgToiwAGGNMiLIAYIwxIcoCgDHGhCgLAMYYE6IsABhjTIj6/yQnrf3zJ8m3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "((losses)).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
