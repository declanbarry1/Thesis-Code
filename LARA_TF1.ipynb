{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a32a81-94fe-49b6-b6a2-10a7c619bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "brand_num = 254 \n",
    "class_num =  178\n",
    "user_emb_dim = brand_num + class_num\n",
    "\n",
    "D_brand_emb_dim = 128\n",
    "D_class_emb_dim = 128\n",
    "\n",
    "G_brand_emb_dim = 128\n",
    "G_class_emb_dim = 128\n",
    "\n",
    "hidden_dim = 128\n",
    "alpha = 0\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "'''D variables'''\n",
    "init = tf.initializers.glorot_normal()\n",
    "D_brand_embs = tf.compat.v1.get_variable('D_brand_embs', [brand_num, D_brand_emb_dim],initializer=init)\n",
    "D_class_embs = tf.compat.v1.get_variable('D_class_embs', [class_num, D_class_emb_dim],initializer=init)\n",
    "# D layer_1\n",
    "D_l1_input_size = user_emb_dim + D_brand_emb_dim + D_class_emb_dim\n",
    "D_W1 = tf.compat.v1.get_variable('D_W1', [D_l1_input_size, hidden_dim],initializer=init)\n",
    "D_b1 = tf.compat.v1.get_variable('D_b1', [1, hidden_dim],initializer=init)\n",
    "\n",
    "\n",
    "D_W2 = tf.compat.v1.get_variable('D_W2', [hidden_dim, hidden_dim],initializer=init)\n",
    "D_b2 = tf.compat.v1.get_variable('D_b2', [1, hidden_dim],initializer=init)\n",
    "\n",
    "D_W3 = tf.compat.v1.get_variable('D_W3', [hidden_dim, 1],initializer=init)\n",
    "D_b3 = tf.compat.v1.get_variable('D_b3', [1, 1],initializer=init)\n",
    "\n",
    "D_params = [D_brand_embs, D_class_embs, D_W1, D_b1, D_W2, D_b2, D_W3, D_b3]\n",
    "\n",
    "'''G variables'''\n",
    "G_brand_embs = tf.compat.v1.get_variable('G_brand_embs', [brand_num, G_brand_emb_dim],initializer=init)\n",
    "G_class_embs = tf.compat.v1.get_variable('G_class_embs', [class_num, G_class_emb_dim],initializer=init)\n",
    "# D layer_1\n",
    "G_l1_input_size =  G_brand_emb_dim + G_class_emb_dim\n",
    "G_W1 = tf.compat.v1.get_variable('G_W1', [G_l1_input_size, hidden_dim],initializer=init)\n",
    "G_b1 = tf.compat.v1.get_variable('G_b1', [1, hidden_dim],initializer=init)\n",
    "G_W2 = tf.compat.v1.get_variable('G_W2', [hidden_dim, hidden_dim],initializer=init)\n",
    "G_b2 = tf.compat.v1.get_variable('G_b2', [1, hidden_dim],initializer=init)\n",
    "G_W3 = tf.compat.v1.get_variable('G_W3', [hidden_dim, user_emb_dim],initializer=init)\n",
    "G_b3 = tf.compat.v1.get_variable('G_b3', [1, user_emb_dim],initializer=init)\n",
    "G_params = [G_brand_embs, G_class_embs, G_W1, G_b1, G_W2, G_b2, G_W3, G_b3]\n",
    "\n",
    "'''placeholder'''\n",
    "brand_id = tf.compat.v1.placeholder(tf.int32)\n",
    "class_id = tf.compat.v1.placeholder(tf.int32)\n",
    "real_user_emb = tf.compat.v1.placeholder(shape = [None, user_emb_dim], dtype = tf.float32)\n",
    "counter_brand_id = tf.compat.v1.placeholder(tf.int32)\n",
    "counter_class_id = tf.compat.v1.placeholder(tf.int32)\n",
    "counter_user_emb = tf.compat.v1.placeholder(shape = [None, user_emb_dim], dtype = tf.float32)\n",
    "\n",
    "'''G'''\n",
    "def generator(brand_id, class_id):\n",
    "    brand_emb = tf.nn.embedding_lookup(G_brand_embs, brand_id)\n",
    "    class_emb = tf.nn.embedding_lookup(G_class_embs, class_id)\n",
    "    brand_class_emb = tf.concat([class_emb, brand_emb], 1)\n",
    "    l1_outputs = tf.nn.sigmoid(tf.matmul(brand_class_emb, G_W1) + G_b1)   \n",
    "    l2_outputs = tf.nn.sigmoid(tf.matmul(l1_outputs, G_W2) + G_b2)\n",
    "    l3_outputs = tf.nn.sigmoid(tf.matmul(l2_outputs, G_W3) + G_b3)\n",
    "   \n",
    "    return l3_outputs\n",
    "\n",
    "'''D'''\n",
    "def discriminator(brand_id, class_id, user_emb):\n",
    "    brand_emb = tf.nn.embedding_lookup(D_brand_embs, brand_id)\n",
    "    class_emb = tf.nn.embedding_lookup(D_class_embs, class_id)\n",
    "    emb = tf.concat([class_emb, brand_emb, user_emb], 1)   \n",
    "    l1_outputs = tf.nn.sigmoid(tf.matmul(emb, D_W1) + D_b1)\n",
    "    l2_outputs = tf.nn.sigmoid(tf.matmul(l1_outputs, D_W2) + D_b2)\n",
    "    D_logit = tf.matmul(l2_outputs, D_W3) + D_b3\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit\n",
    "\n",
    "'''loss'''\n",
    "fake_user_emb = generator(brand_id, class_id)\n",
    "D_real, D_logit_real = discriminator(brand_id, class_id, real_user_emb)\n",
    "D_fake, D_logit_fake = discriminator(brand_id, class_id, fake_user_emb)\n",
    "D_counter, D_logit_counter = discriminator(counter_brand_id, counter_class_id, counter_user_emb)\n",
    "\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss_counter = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_counter, labels=tf.zeros_like(D_logit_counter))) \n",
    "\n",
    "D_regular = alpha * (tf.nn.l2_loss(D_brand_embs) + tf.nn.l2_loss(D_class_embs) + tf.nn.l2_loss(D_W1) + tf.nn.l2_loss(D_b1) + tf.nn.l2_loss(D_W2) + tf.nn.l2_loss(D_b2)) \n",
    "G_regular = alpha * (tf.nn.l2_loss(G_brand_embs) + tf.nn.l2_loss(G_class_embs) + tf.nn.l2_loss(G_W1) + \n",
    "                     tf.nn.l2_loss(G_b1) + tf.nn.l2_loss(G_W2) + tf.nn.l2_loss(G_b2) + tf.nn.l2_loss(G_W2) + tf.nn.l2_loss(G_b2))\n",
    "\n",
    "D_loss = D_loss_real + D_loss_fake + D_loss_counter + D_regular \n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake))) + G_regular\n",
    "\n",
    "'''optimizer'''\n",
    "D_solver = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.001).minimize(D_loss, var_list=D_params)\n",
    "G_solver = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.001).minimize(G_loss, var_list=G_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c33d6-1507-4b67-af91-6bb2ab7d4620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0 p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08165662717074934 G_at_10 0.10506853490650797 G_at_20 0.15356114496603426\n",
      "max p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08165662717074934 G_at_10 0.10506853490650797 G_at_20 0.15356114496603426\n",
      "it 1 p_at_10  0.0223 p_at_20 0.0242 M_at_10 0.07295588778146918 M_at_20 0.07774119524326521 G_at_10 0.10227668897884971 G_at_20 0.14032290954808135\n",
      "max p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08165662717074934 G_at_10 0.10506853490650797 G_at_20 0.15356114496603426\n",
      "it 2 p_at_10  0.02 p_at_20 0.0184 M_at_10 0.06552694721299374 M_at_20 0.06997674992293035 G_at_10 0.09188336320082158 G_at_20 0.11639747520329811\n",
      "max p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08165662717074934 G_at_10 0.10506853490650797 G_at_20 0.15356114496603426\n",
      "it 3 p_at_10  0.0214 p_at_20 0.0237 M_at_10 0.05918789221114802 M_at_20 0.06802622718212392 G_at_10 0.08598557864716654 G_at_20 0.12860011705689517\n",
      "max p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08165662717074934 G_at_10 0.10506853490650797 G_at_20 0.15356114496603426\n",
      "it 4 p_at_10  0.0228 p_at_20 0.0272 M_at_10 0.073671834625323 M_at_20 0.08208656720556425 G_at_10 0.10335636331844761 G_at_20 0.15467560558280524\n",
      "max p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08208656720556425 G_at_10 0.10506853490650797 G_at_20 0.15467560558280524\n",
      "it 5 p_at_10  0.0191 p_at_20 0.0219 M_at_10 0.0658656330749354 M_at_20 0.07674642360103877 G_at_10 0.09124988577636456 G_at_20 0.13604682712841282\n",
      "max p_at_10  0.0237 p_at_20 0.0272 M_at_10 0.07405500184569952 M_at_20 0.08208656720556425 G_at_10 0.10506853490650797 G_at_20 0.15467560558280524\n",
      "it 6 p_at_10  0.0353 p_at_20 0.0263 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 7 p_at_10  0.0251 p_at_20 0.0228 M_at_10 0.06957918050941306 M_at_20 0.07336098225300111 G_at_10 0.09899471846232892 G_at_20 0.1287149775269729\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 8 p_at_10  0.0256 p_at_20 0.0244 M_at_10 0.07690476190476189 M_at_20 0.07587943642105209 G_at_10 0.10960127519876538 G_at_20 0.1378977305577069\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 9 p_at_10  0.0242 p_at_20 0.0237 M_at_10 0.07218530823181986 M_at_20 0.07993032341455554 G_at_10 0.10494604889662178 G_at_20 0.1447101747929451\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 10 p_at_10  0.0265 p_at_20 0.0256 M_at_10 0.07872535991140643 M_at_20 0.08549712240330715 G_at_10 0.11272746997615407 G_at_20 0.1516736812995425\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 11 p_at_10  0.0223 p_at_20 0.0233 M_at_10 0.06788324632178452 M_at_20 0.07582661127699766 G_at_10 0.09377795604113807 G_at_20 0.13344455855337983\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 12 p_at_10  0.0219 p_at_20 0.0223 M_at_10 0.06615356220007382 M_at_20 0.07402276658879332 G_at_10 0.09629212028471698 G_at_20 0.12943988955051808\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 13 p_at_10  0.0237 p_at_20 0.0233 M_at_10 0.06484219269102989 M_at_20 0.0735464411103226 G_at_10 0.09507003731379912 G_at_20 0.1330134049276092\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 14 p_at_10  0.0279 p_at_20 0.0251 M_at_10 0.07259505352528607 M_at_20 0.0807016884990461 G_at_10 0.1086424131538104 G_at_20 0.14699541851875936\n",
      "max p_at_10  0.0353 p_at_20 0.0272 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 15 p_at_10  0.0284 p_at_20 0.0281 M_at_10 0.07192137320044296 M_at_20 0.07875014900646696 G_at_10 0.11350569862275016 G_at_20 0.1527511606418652\n",
      "max p_at_10  0.0353 p_at_20 0.0281 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 16 p_at_10  0.0242 p_at_20 0.0244 M_at_10 0.06681985972683646 M_at_20 0.07104065768206455 G_at_10 0.0963566596573511 G_at_20 0.13102375381108522\n",
      "max p_at_10  0.0353 p_at_20 0.0281 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 17 p_at_10  0.0237 p_at_20 0.0251 M_at_10 0.07015503875968991 M_at_20 0.076581556963383 G_at_10 0.10106234258620318 G_at_20 0.1407210080817468\n",
      "max p_at_10  0.0353 p_at_20 0.0281 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 18 p_at_10  0.0247 p_at_20 0.027 M_at_10 0.06767257290513105 M_at_20 0.07710927014911856 G_at_10 0.09972258992361958 G_at_20 0.14559092569385043\n",
      "max p_at_10  0.0353 p_at_20 0.0281 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.160939892987019\n",
      "it 19 p_at_10  0.0293 p_at_20 0.0302 M_at_10 0.07709671465485418 M_at_20 0.08150321163198261 G_at_10 0.11669756533915711 G_at_20 0.1612660210186254\n",
      "max p_at_10  0.0353 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.1612660210186254\n",
      "it 20 p_at_10  0.026 p_at_20 0.0291 M_at_10 0.07813030638612034 M_at_20 0.08328244100749063 G_at_10 0.11219801043684186 G_at_20 0.15470887491981836\n",
      "max p_at_10  0.0353 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08978800443322726 G_at_10 0.13770209947424258 G_at_20 0.1612660210186254\n",
      "it 21 p_at_10  0.0377 p_at_20 0.0295 M_at_10 0.08639147286821705 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 22 p_at_10  0.0274 p_at_20 0.0249 M_at_10 0.054892026578073086 M_at_20 0.06324077974808769 G_at_10 0.09423182221303217 G_at_20 0.13294016369534276\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 23 p_at_10  0.027 p_at_20 0.0284 M_at_10 0.07858361018826136 M_at_20 0.08109432285181079 G_at_10 0.11518411392338257 G_at_20 0.15212593184135537\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 24 p_at_10  0.0233 p_at_20 0.0281 M_at_10 0.06342561830933924 M_at_20 0.07347288077117738 G_at_10 0.09530074000689334 G_at_20 0.14307200902961723\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 25 p_at_10  0.0321 p_at_20 0.0281 M_at_10 0.08595422665190106 M_at_20 0.08920966593760303 G_at_10 0.12960697071140995 G_at_20 0.16420195051362035\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 26 p_at_10  0.026 p_at_20 0.0286 M_at_10 0.07774824658545589 M_at_20 0.08467419461976305 G_at_10 0.1110864312180997 G_at_20 0.15543884373514463\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 27 p_at_10  0.0288 p_at_20 0.0253 M_at_10 0.08128460686600221 M_at_20 0.08324629537162836 G_at_10 0.12101912731827777 G_at_20 0.14849552513896172\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 28 p_at_10  0.0265 p_at_20 0.0277 M_at_10 0.07469084533038022 M_at_20 0.07751634067646739 G_at_10 0.10932366072269174 G_at_20 0.14973694757384204\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 29 p_at_10  0.0288 p_at_20 0.0277 M_at_10 0.07706792174234034 M_at_20 0.08659601408037218 G_at_10 0.11290294487088846 G_at_20 0.15457243490515393\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 30 p_at_10  0.0293 p_at_20 0.0286 M_at_10 0.07087363110618924 M_at_20 0.07881092396704271 G_at_10 0.10931844179084851 G_at_20 0.1507611863704207\n",
      "max p_at_10  0.0377 p_at_20 0.0302 M_at_10 0.08799926172019196 M_at_20 0.08985345610030203 G_at_10 0.14024981899027325 G_at_20 0.1649612432641108\n",
      "it 31 p_at_10  0.0363 p_at_20 0.0335 M_at_10 0.08424487818383168 M_at_20 0.09456807415004548 G_at_10 0.13076052492565834 G_at_20 0.17678578489511365\n",
      "max p_at_10  0.0377 p_at_20 0.0335 M_at_10 0.08799926172019196 M_at_20 0.09456807415004548 G_at_10 0.14024981899027325 G_at_20 0.17678578489511365\n",
      "it 32 p_at_10  0.0265 p_at_20 0.0274 M_at_10 0.08191583610188262 M_at_20 0.08792731075400813 G_at_10 0.1166498034678461 G_at_20 0.16186654629623604\n",
      "max p_at_10  0.0377 p_at_20 0.0335 M_at_10 0.08799926172019196 M_at_20 0.09456807415004548 G_at_10 0.14024981899027325 G_at_20 0.17678578489511365\n",
      "it 33 p_at_10  0.0298 p_at_20 0.0321 M_at_10 0.08273963332102867 M_at_20 0.09130064113499746 G_at_10 0.11914764384048156 G_at_20 0.1669261261390682\n",
      "max p_at_10  0.0377 p_at_20 0.0335 M_at_10 0.08799926172019196 M_at_20 0.09456807415004548 G_at_10 0.14024981899027325 G_at_20 0.17678578489511365\n",
      "it 34 p_at_10  0.033 p_at_20 0.0302 M_at_10 0.09719453672942044 M_at_20 0.09631969095429387 G_at_10 0.13855314816143646 G_at_20 0.17331419559143008\n",
      "max p_at_10  0.0377 p_at_20 0.0335 M_at_10 0.09719453672942044 M_at_20 0.09631969095429387 G_at_10 0.14024981899027325 G_at_20 0.17678578489511365\n",
      "it 35 p_at_10  0.026 p_at_20 0.0263 M_at_10 0.07136766334440753 M_at_20 0.07848097243194081 G_at_10 0.10894148783486392 G_at_20 0.15221929134960713\n",
      "max p_at_10  0.0377 p_at_20 0.0335 M_at_10 0.09719453672942044 M_at_20 0.09631969095429387 G_at_10 0.14024981899027325 G_at_20 0.17678578489511365\n",
      "it 36 p_at_10  0.0395 p_at_20 0.0321 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 37 p_at_10  0.0349 p_at_20 0.0312 M_at_10 0.09929771133259505 M_at_20 0.10511530139726914 G_at_10 0.14366975463249151 G_at_20 0.1795902083494423\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 38 p_at_10  0.033 p_at_20 0.033 M_at_10 0.07616002214839425 M_at_20 0.08734602666302213 G_at_10 0.12241762921657984 G_at_20 0.1699217106246464\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 39 p_at_10  0.0326 p_at_20 0.0293 M_at_10 0.07591768180140274 M_at_20 0.08579139486542228 G_at_10 0.1145697390939752 G_at_20 0.15479415544149336\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 40 p_at_10  0.0326 p_at_20 0.0302 M_at_10 0.0813049095607235 M_at_20 0.09014947432135495 G_at_10 0.12206522381571656 G_at_20 0.16093057763279572\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 41 p_at_10  0.0279 p_at_20 0.03 M_at_10 0.08775932078257659 M_at_20 0.0962009421007549 G_at_10 0.12262126822282358 G_at_20 0.17352283902230023\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 42 p_at_10  0.0284 p_at_20 0.0281 M_at_10 0.07091177556293836 M_at_20 0.07987006211105059 G_at_10 0.10742227374625822 G_at_20 0.1502970850972918\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 43 p_at_10  0.0316 p_at_20 0.0326 M_at_10 0.07969453672942045 M_at_20 0.08319454109035794 G_at_10 0.12149473999657229 G_at_20 0.16215727631177962\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 44 p_at_10  0.0326 p_at_20 0.0321 M_at_10 0.08251559616094499 M_at_20 0.0909448591377636 G_at_10 0.12333882370283746 G_at_20 0.1720273637874258\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 45 p_at_10  0.0307 p_at_20 0.0326 M_at_10 0.07840900701365817 M_at_20 0.08934588218028093 G_at_10 0.1230104085922565 G_at_20 0.1775161729019222\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 46 p_at_10  0.0288 p_at_20 0.0298 M_at_10 0.05751495016611295 M_at_20 0.06520448414057266 G_at_10 0.0964501830613957 G_at_20 0.13986532205107033\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 47 p_at_10  0.0321 p_at_20 0.0335 M_at_10 0.08088132152085642 M_at_20 0.09086318301711327 G_at_10 0.12038682216671903 G_at_20 0.17245327576989383\n",
      "max p_at_10  0.0395 p_at_20 0.0335 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 48 p_at_10  0.0358 p_at_20 0.0358 M_at_10 0.08723514211886303 M_at_20 0.09127496514826415 G_at_10 0.1327754983303322 G_at_20 0.17717807120111975\n",
      "max p_at_10  0.0395 p_at_20 0.0358 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 49 p_at_10  0.0353 p_at_20 0.0319 M_at_10 0.10046880767810999 M_at_20 0.10284009351551561 G_at_10 0.14660908239833215 G_at_20 0.18019002534225034\n",
      "max p_at_10  0.0395 p_at_20 0.0358 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 50 p_at_10  0.0265 p_at_20 0.0288 M_at_10 0.06573717238833518 M_at_20 0.07152127268950424 G_at_10 0.10193178409774814 G_at_20 0.1460473880863051\n",
      "max p_at_10  0.0395 p_at_20 0.0358 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 51 p_at_10  0.0349 p_at_20 0.0353 M_at_10 0.08181722301323631 M_at_20 0.08522867162057102 G_at_10 0.12415895188008866 G_at_20 0.16153379365332557\n",
      "max p_at_10  0.0395 p_at_20 0.0358 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 52 p_at_10  0.0405 p_at_20 0.0335 M_at_10 0.09380583241048357 M_at_20 0.09928501434126388 G_at_10 0.14459823528225035 G_at_20 0.1791932864610215\n",
      "max p_at_10  0.0405 p_at_20 0.0358 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 53 p_at_10  0.0302 p_at_20 0.0316 M_at_10 0.07976651901070507 M_at_20 0.08418027184986648 G_at_10 0.11762237730470132 G_at_20 0.16059645157018076\n",
      "max p_at_10  0.0405 p_at_20 0.0358 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "it 54 p_at_10  0.0405 p_at_20 0.0381 M_at_10 0.08417663344407529 M_at_20 0.09287683863250087 G_at_10 0.13402094086746805 G_at_20 0.18337697111210627\n",
      "max p_at_10  0.0405 p_at_20 0.0381 M_at_10 0.10533361018826135 M_at_20 0.1103004730008114 G_at_10 0.15666542227431032 G_at_20 0.1908463792618742\n",
      "WARNING:tensorflow:From /home/declanbarrycbc1/.local/lib/python3.8/site-packages/tensorflow/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "it 55 p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.10373815473145878 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 56 p_at_10  0.0381 p_at_20 0.0342 M_at_10 0.08849698535745047 M_at_20 0.08930575267852069 G_at_10 0.1360568371395203 G_at_20 0.167384416022575\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 57 p_at_10  0.0326 p_at_20 0.0356 M_at_10 0.07383536360280546 M_at_20 0.0818961456247078 G_at_10 0.11449378135517518 G_at_20 0.16293343423951348\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 58 p_at_10  0.0386 p_at_20 0.0374 M_at_10 0.09338778146917681 M_at_20 0.09582724318941378 G_at_10 0.14453974931989125 G_at_20 0.1808151403462539\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 59 p_at_10  0.0386 p_at_20 0.0402 M_at_10 0.08974529346622369 M_at_20 0.09801079488133989 G_at_10 0.13951820135418633 G_at_20 0.19238635841495946\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 60 p_at_10  0.0367 p_at_20 0.0377 M_at_10 0.08365540789959394 M_at_20 0.08930582220277304 G_at_10 0.13130964568497347 G_at_20 0.1763279445870685\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 61 p_at_10  0.0433 p_at_20 0.0351 M_at_10 0.09750061523317335 M_at_20 0.09391018739981949 G_at_10 0.1512314890609849 G_at_20 0.17150489206763395\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 62 p_at_10  0.0372 p_at_20 0.037 M_at_10 0.08541620524178663 M_at_20 0.09464467713675027 G_at_10 0.13127644893059737 G_at_20 0.18195958976790128\n",
      "max p_at_10  0.046 p_at_20 0.0409 M_at_10 0.10872277593207827 M_at_20 0.1103004730008114 G_at_10 0.16872439921725657 G_at_20 0.19968744041905176\n",
      "it 63 p_at_10  0.046 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "max p_at_10  0.046 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 64 p_at_10  0.0479 p_at_20 0.0465 M_at_10 0.1199864648701858 M_at_20 0.12233601857658664 G_at_10 0.1749080017243598 G_at_20 0.2151071674407672\n",
      "max p_at_10  0.0479 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 65 p_at_10  0.0437 p_at_20 0.0453 M_at_10 0.10509025470653378 M_at_20 0.11712242645015883 G_at_10 0.15708565584460063 G_at_20 0.2116525055877258\n",
      "max p_at_10  0.0479 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 66 p_at_10  0.0493 p_at_20 0.0456 M_at_10 0.10352990033222591 M_at_20 0.10800356575502372 G_at_10 0.16484755967705625 G_at_20 0.21195798303147287\n",
      "max p_at_10  0.0493 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 67 p_at_10  0.0479 p_at_20 0.0458 M_at_10 0.09684552373921146 M_at_20 0.10610103177792152 G_at_10 0.1487372298703312 G_at_20 0.1989826398299923\n",
      "max p_at_10  0.0493 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 68 p_at_10  0.0479 p_at_20 0.0412 M_at_10 0.11786544850498337 M_at_20 0.12265551963718377 G_at_10 0.17675307967404114 G_at_20 0.21428727591139124\n",
      "max p_at_10  0.0493 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 69 p_at_10  0.0414 p_at_20 0.0419 M_at_10 0.11177872699467384 M_at_20 0.11909163011111495 G_at_10 0.15786810628020218 G_at_20 0.2126669842548646\n",
      "max p_at_10  0.0493 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 70 p_at_10  0.0419 p_at_20 0.0412 M_at_10 0.10631819859726835 M_at_20 0.11011421380036672 G_at_10 0.15896969751627116 G_at_20 0.19567913645379065\n",
      "max p_at_10  0.0493 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 71 p_at_10  0.0447 p_at_20 0.043 M_at_10 0.11271576227390179 M_at_20 0.10921302965169256 G_at_10 0.1666693612919322 G_at_20 0.20059099007921807\n",
      "max p_at_10  0.0493 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 72 p_at_10  0.0563 p_at_20 0.0463 M_at_10 0.11335310868533457 M_at_20 0.11421658907800047 G_at_10 0.17789751543188798 G_at_20 0.2059616802203751\n",
      "max p_at_10  0.0563 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 73 p_at_10  0.0479 p_at_20 0.0433 M_at_10 0.11891957364341083 M_at_20 0.12090475276930385 G_at_10 0.17309295622630652 G_at_20 0.21009762062727055\n",
      "max p_at_10  0.0563 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 74 p_at_10  0.0488 p_at_20 0.044 M_at_10 0.10299528833928061 M_at_20 0.10419907402046143 G_at_10 0.15054319249986542 G_at_20 0.18580744600714488\n",
      "max p_at_10  0.0563 p_at_20 0.0465 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 75 p_at_10  0.053 p_at_20 0.0467 M_at_10 0.11547916117351333 M_at_20 0.11696086966635601 G_at_10 0.1701073971219823 G_at_20 0.20445871693993806\n",
      "max p_at_10  0.0563 p_at_20 0.0467 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 76 p_at_10  0.0409 p_at_20 0.0419 M_at_10 0.08748867970960995 M_at_20 0.09420969982389991 G_at_10 0.13610227706583386 G_at_20 0.18818384806058758\n",
      "max p_at_10  0.0563 p_at_20 0.0467 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 77 p_at_10  0.0391 p_at_20 0.0391 M_at_10 0.0821120954841885 M_at_20 0.0858127259628046 G_at_10 0.13092058012846308 G_at_20 0.1732012346571558\n",
      "max p_at_10  0.0563 p_at_20 0.0467 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 78 p_at_10  0.0484 p_at_20 0.0453 M_at_10 0.09630798572659037 M_at_20 0.10048206662398648 G_at_10 0.1505698721893865 G_at_20 0.19385749345231904\n",
      "max p_at_10  0.0563 p_at_20 0.0467 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 79 p_at_10  0.0507 p_at_20 0.0502 M_at_10 0.10180890857635043 M_at_20 0.10928956697894646 G_at_10 0.16049780223733537 G_at_20 0.19959229963702432\n",
      "max p_at_10  0.0563 p_at_20 0.0502 M_at_10 0.12187938353636028 M_at_20 0.12561703181599324 G_at_10 0.1810547328230426 G_at_20 0.2240147970762753\n",
      "it 80 p_at_10  0.0553 p_at_20 0.0509 M_at_10 0.12271397809769902 M_at_20 0.11881191325736984 G_at_10 0.18258965750676737 G_at_20 0.21349376161028577\n",
      "max p_at_10  0.0563 p_at_20 0.0509 M_at_10 0.12271397809769902 M_at_20 0.12561703181599324 G_at_10 0.18258965750676737 G_at_20 0.2240147970762753\n",
      "it 81 p_at_10  0.0558 p_at_20 0.0463 M_at_10 0.1339116525163037 M_at_20 0.1318313882322013 G_at_10 0.19361434658853116 G_at_20 0.2227037370286344\n",
      "max p_at_10  0.0563 p_at_20 0.0509 M_at_10 0.1339116525163037 M_at_20 0.1318313882322013 G_at_10 0.19361434658853116 G_at_20 0.2240147970762753\n"
     ]
    }
   ],
   "source": [
    "tf_config = tf.compat.v1.ConfigProto()  \n",
    "tf_config.gpu_options.allow_growth = True  \n",
    "saver = tf.compat.v1.train.Saver(max_to_keep= 5)\n",
    "sess = tf.compat.v1.Session(config=tf_config) \n",
    "#sess = tf.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "batch_size = 1024\n",
    "c_batch_size = batch_size*2\n",
    "\n",
    "max_p_at_10 = 0\n",
    "max_p_at_20 = 0\n",
    "max_M_at_10 = 0\n",
    "max_M_at_20 = 0 \n",
    "max_G_at_10 = 0\n",
    "max_G_at_20 = 0\n",
    "p_10_to_save = []\n",
    "p_20_to_save = []\n",
    "M_10_to_save = []\n",
    "M_20_to_save = []\n",
    "G_10_to_save = []\n",
    "G_20_to_save = []\n",
    "\n",
    "'''train'''\n",
    "for it in range(500):\n",
    "    D_range = 4\n",
    "    G_range = 1   \n",
    "    for D_it in range(D_range):\n",
    "        index = 0\n",
    "        index_2 = 0\n",
    "        while index < 198488:\n",
    "             if index + batch_size <= 198488:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, index + batch_size)\n",
    "                 index = index + batch_size\n",
    "             else:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, 198488)\n",
    "                 index = 198488\n",
    "             counter_brand_batch, counter_class_batch, counter_user_batch = support.get_counter_batch(index_2, index_2 + c_batch_size)\n",
    "             index_2 = index_2 + c_batch_size\n",
    "             _, D_loss_now = sess.run([D_solver, D_loss], \n",
    "                                      feed_dict={brand_id:train_brand_batch, class_id:train_class_batch, real_user_emb:train_user_emb_batch,\n",
    "                                                 counter_brand_id:counter_brand_batch, counter_class_id:counter_class_batch, counter_user_emb:counter_user_batch})  \n",
    "  \n",
    "    for G_it in range(G_range):\n",
    "        index = 0\n",
    "        while index < 198488:\n",
    "             if index + batch_size <= 198488:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, index + batch_size)\n",
    "                 index = index + batch_size \n",
    "             else:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, 198488)\n",
    "                 index = 198488\n",
    "             _, G_loss_now = sess.run([G_solver, G_loss], feed_dict={brand_id:train_brand_batch, class_id:train_class_batch}) \n",
    "        \n",
    "    if it % 1 == 0:\n",
    "        test_item_batch, test_brand_batch, test_classid_batch = support.get_testdata()\n",
    "        test_G_user = sess.run(fake_user_emb, feed_dict={brand_id:test_brand_batch, class_id:test_classid_batch})\n",
    "        \n",
    "        p_at_10,p_at_20,M_at_10,M_at_20,G_at_10,G_at_20 = support.test(test_item_batch, test_G_user)\n",
    "        if p_at_10 > max_p_at_10:           \n",
    "            saver.save(sess, \"model_lara/model.ckpt\", global_step=it,) \n",
    "            max_p_at_10 = p_at_10\n",
    "        p_10_to_save.append(p_at_10)\n",
    "        if p_at_20 > max_p_at_20:\n",
    "            max_p_at_20 = p_at_20\n",
    "        p_20_to_save.append(p_at_20)\n",
    "        if M_at_10 > max_M_at_10:\n",
    "            max_M_at_10 = M_at_10\n",
    "        M_10_to_save.append(M_at_10)\n",
    "        if M_at_20 > max_M_at_20:\n",
    "            max_M_at_20 = M_at_20\n",
    "        M_20_to_save.append(M_at_20)\n",
    "        if G_at_10 > max_G_at_10:\n",
    "            max_G_at_10 = G_at_10\n",
    "        G_10_to_save.append(G_at_10)\n",
    "        if G_at_20 > max_G_at_20:\n",
    "            max_G_at_20 = G_at_20\n",
    "        G_20_to_save.append(G_at_20)\n",
    "      \n",
    "        print('it', it, 'p_at_10 ', p_at_10, 'p_at_20', p_at_20,'M_at_10',M_at_10,'M_at_20',M_at_20,'G_at_10',G_at_10,'G_at_20',G_at_20)\n",
    "        print('max p_at_10 ', max_p_at_10, 'p_at_20', max_p_at_20,'M_at_10',max_M_at_10,'M_at_20',max_M_at_20,'G_at_10',max_G_at_10,'G_at_20',max_G_at_20)\n",
    "    if it % 100 == 0:\n",
    "        pd.DataFrame(p_10_to_save).to_csv('p10.csv')\n",
    "        pd.DataFrame(p_20_to_save).to_csv('p20.csv')\n",
    "        pd.DataFrame(M_10_to_save).to_csv('m10.csv')\n",
    "        pd.DataFrame(M_20_to_save).to_csv('m20.csv')\n",
    "        pd.DataFrame(G_10_to_save).to_csv('g10.csv')\n",
    "        pd.DataFrame(G_20_to_save).to_csv('g20.csv')\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
