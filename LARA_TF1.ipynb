{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d3c1f8-e4a4-4e50-9ea5-982a6487934d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import support\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012d0c06-a56e-4644-b41d-b6f70fddae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "brand_num = 254 \n",
    "class_num =  178\n",
    "user_emb_dim = brand_num + class_num\n",
    "\n",
    "D_brand_emb_dim = 128\n",
    "D_class_emb_dim = 128\n",
    "\n",
    "G_brand_emb_dim = 128\n",
    "G_class_emb_dim = 128\n",
    "\n",
    "hidden_dim = 128\n",
    "alpha = 0\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "'''D variables'''\n",
    "init = tf.initializers.glorot_normal()\n",
    "D_brand_embs = tf.compat.v1.get_variable('D_brand_embs', [brand_num, D_brand_emb_dim],initializer=init)\n",
    "D_class_embs = tf.compat.v1.get_variable('D_class_embs', [class_num, D_class_emb_dim],initializer=init)\n",
    "# D layer_1\n",
    "D_l1_input_size = user_emb_dim + D_brand_emb_dim + D_class_emb_dim\n",
    "D_W1 = tf.compat.v1.get_variable('D_W1', [D_l1_input_size, hidden_dim],initializer=init)\n",
    "D_b1 = tf.compat.v1.get_variable('D_b1', [1, hidden_dim],initializer=init)\n",
    "\n",
    "\n",
    "D_W2 = tf.compat.v1.get_variable('D_W2', [hidden_dim, hidden_dim],initializer=init)\n",
    "D_b2 = tf.compat.v1.get_variable('D_b2', [1, hidden_dim],initializer=init)\n",
    "\n",
    "D_W3 = tf.compat.v1.get_variable('D_W3', [hidden_dim, 1],initializer=init)\n",
    "D_b3 = tf.compat.v1.get_variable('D_b3', [1, 1],initializer=init)\n",
    "\n",
    "D_params = [D_brand_embs, D_class_embs, D_W1, D_b1, D_W2, D_b2, D_W3, D_b3]\n",
    "\n",
    "'''G variables'''\n",
    "G_brand_embs = tf.compat.v1.get_variable('G_brand_embs', [brand_num, G_brand_emb_dim],initializer=init)\n",
    "G_class_embs = tf.compat.v1.get_variable('G_class_embs', [class_num, G_class_emb_dim],initializer=init)\n",
    "# D layer_1\n",
    "G_l1_input_size =  G_brand_emb_dim + G_class_emb_dim\n",
    "G_W1 = tf.compat.v1.get_variable('G_W1', [G_l1_input_size, hidden_dim],initializer=init)\n",
    "G_b1 = tf.compat.v1.get_variable('G_b1', [1, hidden_dim],initializer=init)\n",
    "G_W2 = tf.compat.v1.get_variable('G_W2', [hidden_dim, hidden_dim],initializer=init)\n",
    "G_b2 = tf.compat.v1.get_variable('G_b2', [1, hidden_dim],initializer=init)\n",
    "G_W3 = tf.compat.v1.get_variable('G_W3', [hidden_dim, user_emb_dim],initializer=init)\n",
    "G_b3 = tf.compat.v1.get_variable('G_b3', [1, user_emb_dim],initializer=init)\n",
    "G_params = [G_brand_embs, G_class_embs, G_W1, G_b1, G_W2, G_b2, G_W3, G_b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d38018a-9958-4c0c-a0a1-1a60ac95e71a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''G'''\n",
    "def generator(brand_id, class_id):\n",
    "    brand_emb = tf.nn.embedding_lookup(G_brand_embs, brand_id)\n",
    "    class_emb = tf.nn.embedding_lookup(G_class_embs, class_id)\n",
    "    brand_class_emb = tf.concat([class_emb, brand_emb], 1)\n",
    "    l1_outputs = tf.nn.sigmoid(tf.matmul(brand_class_emb, G_W1) + G_b1)   \n",
    "    l2_outputs = tf.nn.sigmoid(tf.matmul(l1_outputs, G_W2) + G_b2)\n",
    "    l3_outputs = tf.nn.sigmoid(tf.matmul(l2_outputs, G_W3) + G_b3)\n",
    "   \n",
    "    return l3_outputs\n",
    "\n",
    "'''D'''\n",
    "def discriminator(brand_id, class_id, user_emb):\n",
    "    brand_emb = tf.nn.embedding_lookup(D_brand_embs, brand_id)\n",
    "    class_emb = tf.nn.embedding_lookup(D_class_embs, class_id)\n",
    "    emb = tf.concat([class_emb, brand_emb, user_emb], 1)   \n",
    "    l1_outputs = tf.nn.sigmoid(tf.matmul(emb, D_W1) + D_b1)\n",
    "    l2_outputs = tf.nn.sigmoid(tf.matmul(l1_outputs, D_W2) + D_b2)\n",
    "    D_logit = tf.matmul(l2_outputs, D_W3) + D_b3\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6342816d-a7a5-47c6-abda-2c3888d35617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''placeholder'''\n",
    "brand_id = tf.compat.v1.placeholder(tf.int32)\n",
    "class_id = tf.compat.v1.placeholder(tf.int32)\n",
    "real_user_emb = tf.compat.v1.placeholder(shape = [None, user_emb_dim], dtype = tf.float32)\n",
    "counter_brand_id = tf.compat.v1.placeholder(tf.int32)\n",
    "counter_class_id = tf.compat.v1.placeholder(tf.int32)\n",
    "counter_user_emb = tf.compat.v1.placeholder(shape = [None, user_emb_dim], dtype = tf.float32)\n",
    "#gp = tf.compat.v1.placeholder(shape = [None, ], dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08df5794-25d5-40aa-9e2b-9dddf35053f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loss'''\n",
    "fake_user_emb = generator(brand_id, class_id)\n",
    "D_real, D_logit_real = discriminator(brand_id, class_id, real_user_emb)\n",
    "D_fake, D_logit_fake = discriminator(brand_id, class_id, fake_user_emb)\n",
    "D_counter, D_logit_counter = discriminator(counter_brand_id, counter_class_id, counter_user_emb)\n",
    "\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss_counter = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_counter, labels=tf.zeros_like(D_logit_counter))) \n",
    "\n",
    "D_regular = alpha * (tf.nn.l2_loss(D_brand_embs) + tf.nn.l2_loss(D_class_embs) + tf.nn.l2_loss(D_W1) + tf.nn.l2_loss(D_b1) + tf.nn.l2_loss(D_W2) + tf.nn.l2_loss(D_b2)) \n",
    "G_regular = alpha * (tf.nn.l2_loss(G_brand_embs) + tf.nn.l2_loss(G_class_embs) + tf.nn.l2_loss(G_W1) + \n",
    "                     tf.nn.l2_loss(G_b1) + tf.nn.l2_loss(G_W2) + tf.nn.l2_loss(G_b2) + tf.nn.l2_loss(G_W2) + tf.nn.l2_loss(G_b2))\n",
    "\n",
    "D_loss = D_loss_real + D_loss_fake + D_loss_counter + D_regular \n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake))) + G_regular\n",
    "\n",
    "#D_loss = tf.reduce_mean(D_logit_fake) - tf.reduce_mean(D_logit_real) + tf.reduce_mean(D_logit_counter)\n",
    "#G_loss = -tf.reduce_mean(D_logit_fake)\n",
    "'''optimizer'''\n",
    "D_solver = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.001).minimize(D_loss, var_list=D_params)\n",
    "G_solver = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.001).minimize(G_loss, var_list=G_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014c33d6-1507-4b67-af91-6bb2ab7d4620",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0 p_at_10:  0.0084 G_at_10 0.04663843117833474 M_at_10:  0.03531007751937984 p_at_20:  0.0065 M_at_20:  0.03841762650514181 G_at_20 0.05825375525684858\n",
      "max p_at_10  0.0084 p_at_20 0.0065 M_at_10 0.03531007751937984 M_at_20 0.03841762650514181 G_at_10 0.04663843117833474 G_at_20 0.05825375525684858\n",
      "it 1 p_at_10:  0.007 G_at_10 0.03833379319733576 M_at_10:  0.029198966408268735 p_at_20:  0.0056 M_at_20:  0.032025140162515064 G_at_20 0.04880483860978903\n",
      "max p_at_10  0.0084 p_at_20 0.0065 M_at_10 0.03531007751937984 M_at_20 0.03841762650514181 G_at_10 0.04663843117833474 G_at_20 0.05825375525684858\n",
      "it 2 p_at_10:  0.0074 G_at_10 0.035406177473254793 M_at_10:  0.022956810631229233 p_at_20:  0.0074 M_at_20:  0.027073165172920372 G_at_20 0.05101777573950561\n",
      "max p_at_10  0.0084 p_at_20 0.0074 M_at_10 0.03531007751937984 M_at_20 0.03841762650514181 G_at_10 0.04663843117833474 G_at_20 0.05825375525684858\n",
      "it 3 p_at_10:  0.0079 G_at_10 0.04473374347827163 M_at_10:  0.03465116279069767 p_at_20:  0.0074 M_at_20:  0.03796939208901913 G_at_20 0.05879384020238129\n",
      "max p_at_10  0.0084 p_at_20 0.0074 M_at_10 0.03531007751937984 M_at_20 0.03841762650514181 G_at_10 0.04663843117833474 G_at_20 0.05879384020238129\n",
      "it 4 p_at_10:  0.0093 G_at_10 0.049228768925791984 M_at_10:  0.037033960871170175 p_at_20:  0.0063 M_at_20:  0.03896472542505374 G_at_20 0.05637246327337776\n",
      "max p_at_10  0.0093 p_at_20 0.0074 M_at_10 0.037033960871170175 M_at_20 0.03896472542505374 G_at_10 0.049228768925791984 G_at_20 0.05879384020238129\n",
      "it 5 p_at_10:  0.0079 G_at_10 0.04396459585638674 M_at_10:  0.03332041343669251 p_at_20:  0.0058 M_at_20:  0.03565012051332161 G_at_20 0.053063082444423065\n",
      "max p_at_10  0.0093 p_at_20 0.0074 M_at_10 0.037033960871170175 M_at_20 0.03896472542505374 G_at_10 0.049228768925791984 G_at_20 0.05879384020238129\n",
      "it 6 p_at_10:  0.0074 G_at_10 0.041100954562354707 M_at_10:  0.031135105204872646 p_at_20:  0.0063 M_at_20:  0.034273205035138934 G_at_20 0.052931989599084545\n",
      "max p_at_10  0.0093 p_at_20 0.0074 M_at_10 0.037033960871170175 M_at_20 0.03896472542505374 G_at_10 0.049228768925791984 G_at_20 0.05879384020238129\n",
      "it 7 p_at_10:  0.0084 G_at_10 0.04588317292976408 M_at_10:  0.035406053894425984 p_at_20:  0.0058 M_at_20:  0.0380523264305394 G_at_20 0.05458704685536865\n",
      "max p_at_10  0.0093 p_at_20 0.0074 M_at_10 0.037033960871170175 M_at_20 0.03896472542505374 G_at_10 0.049228768925791984 G_at_20 0.05879384020238129\n",
      "it 8 p_at_10:  0.0056 G_at_10 0.038397328223363746 M_at_10:  0.03268733850129199 p_at_20:  0.0067 M_at_20:  0.036850495405826966 G_at_20 0.05587954868644049\n",
      "max p_at_10  0.0093 p_at_20 0.0074 M_at_10 0.037033960871170175 M_at_20 0.03896472542505374 G_at_10 0.049228768925791984 G_at_20 0.05879384020238129\n",
      "it 9 p_at_10:  0.0093 G_at_10 0.048238373777781715 M_at_10:  0.0369047619047619 p_at_20:  0.0079 M_at_20:  0.039862320661874256 G_at_20 0.06113861166706818\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.037033960871170175 M_at_20 0.039862320661874256 G_at_10 0.049228768925791984 G_at_20 0.06113861166706818\n",
      "it 10 p_at_10:  0.0065 G_at_10 0.03671385086887086 M_at_10:  0.028194905869324473 p_at_20:  0.0051 M_at_20:  0.030489952444016814 G_at_20 0.045756034387210986\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.037033960871170175 M_at_20 0.039862320661874256 G_at_10 0.049228768925791984 G_at_20 0.06113861166706818\n",
      "it 11 p_at_10:  0.0065 G_at_10 0.03625084464344224 M_at_10:  0.026917681801402735 p_at_20:  0.0053 M_at_20:  0.029613493741400713 G_at_20 0.046573665695469474\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.037033960871170175 M_at_20 0.039862320661874256 G_at_10 0.049228768925791984 G_at_20 0.06113861166706818\n",
      "it 12 p_at_10:  0.0079 G_at_10 0.0422903530630355 M_at_10:  0.03090808416389812 p_at_20:  0.0063 M_at_20:  0.034029800948405596 G_at_20 0.05392031513926915\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.037033960871170175 M_at_20 0.039862320661874256 G_at_10 0.049228768925791984 G_at_20 0.06113861166706818\n",
      "it 13 p_at_10:  0.0084 G_at_10 0.048606410496144274 M_at_10:  0.03766703580657069 p_at_20:  0.0067 M_at_20:  0.03988957187243601 G_at_20 0.05978024860601628\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.03766703580657069 M_at_20 0.03988957187243601 G_at_10 0.049228768925791984 G_at_20 0.06113861166706818\n",
      "it 14 p_at_10:  0.0074 G_at_10 0.04554720189385133 M_at_10:  0.036478405315614616 p_at_20:  0.007 M_at_20:  0.03821900919298139 G_at_20 0.05759406546517149\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.03766703580657069 M_at_20 0.03988957187243601 G_at_10 0.049228768925791984 G_at_20 0.06113861166706818\n",
      "it 15 p_at_10:  0.0079 G_at_10 0.04703408444999898 M_at_10:  0.03691029900332225 p_at_20:  0.0072 M_at_20:  0.040652014983680325 G_at_20 0.06198753993505829\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.03766703580657069 M_at_20 0.040652014983680325 G_at_10 0.049228768925791984 G_at_20 0.06198753993505829\n",
      "it 16 p_at_10:  0.0093 G_at_10 0.051635563621235975 M_at_10:  0.038925802879291246 p_at_20:  0.007 M_at_20:  0.04194841286424554 G_at_20 0.06313388981204421\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 17 p_at_10:  0.0084 G_at_10 0.045073822645067395 M_at_10:  0.032912513842746405 p_at_20:  0.007 M_at_20:  0.03576238027458417 G_at_20 0.056653635418364386\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 18 p_at_10:  0.007 G_at_10 0.037532523719948696 M_at_10:  0.02746770025839793 p_at_20:  0.007 M_at_20:  0.030194025460783327 G_at_20 0.05110380194914151\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 19 p_at_10:  0.0074 G_at_10 0.035225995224902 M_at_10:  0.02339608711701735 p_at_20:  0.0056 M_at_20:  0.025191795488613115 G_at_20 0.0432808180932412\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 20 p_at_10:  0.0084 G_at_10 0.04030427900332387 M_at_10:  0.028331487633813213 p_at_20:  0.007 M_at_20:  0.03155846851127289 G_at_20 0.05311073256318338\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 21 p_at_10:  0.006 G_at_10 0.03792859892026646 M_at_10:  0.03062015503875969 p_at_20:  0.0056 M_at_20:  0.03343250968277968 G_at_20 0.04929267072622058\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 22 p_at_10:  0.007 G_at_10 0.030500053385285015 M_at_10:  0.01881690660760428 p_at_20:  0.0058 M_at_20:  0.02038057046192981 G_at_20 0.03767920688930863\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 23 p_at_10:  0.0084 G_at_10 0.037672695816687966 M_at_10:  0.02422111480251015 p_at_20:  0.0063 M_at_20:  0.026776031386154506 G_at_20 0.047204571977506264\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 24 p_at_10:  0.0093 G_at_10 0.04026307525638708 M_at_10:  0.024274640088593574 p_at_20:  0.0067 M_at_20:  0.02716622287001724 G_at_20 0.050825637239515546\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 25 p_at_10:  0.006 G_at_10 0.029464098949747605 M_at_10:  0.02023809523809524 p_at_20:  0.0056 M_at_20:  0.02302129109440651 G_at_20 0.04086197274438449\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 26 p_at_10:  0.0056 G_at_10 0.034671607313298713 M_at_10:  0.02796234772978959 p_at_20:  0.0051 M_at_20:  0.02780774325233969 G_at_20 0.042758823636409087\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 27 p_at_10:  0.0074 G_at_10 0.03218826037607905 M_at_10:  0.02023255813953488 p_at_20:  0.006 M_at_20:  0.02327126124249747 G_at_20 0.04299900302905737\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 28 p_at_10:  0.0084 G_at_10 0.043234137894876616 M_at_10:  0.0310594315245478 p_at_20:  0.0063 M_at_20:  0.03382067041365767 G_at_20 0.05363373298080804\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 29 p_at_10:  0.0079 G_at_10 0.040983366829961926 M_at_10:  0.029108527131782944 p_at_20:  0.007 M_at_20:  0.03236062353259416 G_at_20 0.05382581065184453\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 30 p_at_10:  0.0074 G_at_10 0.044797980000935066 M_at_10:  0.03544481358434847 p_at_20:  0.0058 M_at_20:  0.037408826443674166 G_at_20 0.05384020011691836\n",
      "max p_at_10  0.0093 p_at_20 0.0079 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 31 p_at_10:  0.0093 G_at_10 0.04435077217270801 M_at_10:  0.03092838685861942 p_at_20:  0.0081 M_at_20:  0.03240617433701889 G_at_20 0.05752864408678123\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 32 p_at_10:  0.0084 G_at_10 0.04360516058239114 M_at_10:  0.03156146179401993 p_at_20:  0.0072 M_at_20:  0.0356557432056028 G_at_20 0.0587516449674879\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 33 p_at_10:  0.0084 G_at_10 0.04351827476480776 M_at_10:  0.03145810262089332 p_at_20:  0.0067 M_at_20:  0.03440311360625998 G_at_20 0.054281817592178656\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 34 p_at_10:  0.0079 G_at_10 0.03704604201643893 M_at_10:  0.02583794758213363 p_at_20:  0.0072 M_at_20:  0.0303495102708509 G_at_20 0.05349463135131494\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 35 p_at_10:  0.007 G_at_10 0.038369287013350954 M_at_10:  0.030095976375046143 p_at_20:  0.0072 M_at_20:  0.033703927171779426 G_at_20 0.05441414682709486\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 36 p_at_10:  0.0074 G_at_10 0.03753560650199104 M_at_10:  0.026478405315614618 p_at_20:  0.0067 M_at_20:  0.030074918621430247 G_at_20 0.05141638535259658\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 37 p_at_10:  0.007 G_at_10 0.035898076348583115 M_at_10:  0.025638612033960874 p_at_20:  0.0053 M_at_20:  0.02806397043329148 G_at_20 0.045119040209499195\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 38 p_at_10:  0.0079 G_at_10 0.040889209178983255 M_at_10:  0.02939830195644149 p_at_20:  0.0077 M_at_20:  0.03360940093498233 G_at_20 0.0566785413775751\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 39 p_at_10:  0.0079 G_at_10 0.0429444738294534 M_at_10:  0.03211886304909561 p_at_20:  0.0065 M_at_20:  0.03547073897135097 G_at_20 0.055630067164778495\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 40 p_at_10:  0.0074 G_at_10 0.038485210280322445 M_at_10:  0.02875968992248062 p_at_20:  0.0081 M_at_20:  0.033830978453071474 G_at_20 0.057581244557255856\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 41 p_at_10:  0.007 G_at_10 0.03701608543669289 M_at_10:  0.027209302325581396 p_at_20:  0.0063 M_at_20:  0.031002229644500508 G_at_20 0.050338082819327494\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 42 p_at_10:  0.006 G_at_10 0.029994817765953873 M_at_10:  0.022253599114064233 p_at_20:  0.0056 M_at_20:  0.02565340751999259 G_at_20 0.04275007580483013\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 43 p_at_10:  0.0074 G_at_10 0.03545184819988664 M_at_10:  0.02501291989664083 p_at_20:  0.0077 M_at_20:  0.0279635065017382 G_at_20 0.05199759563209352\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 44 p_at_10:  0.007 G_at_10 0.033405191023627545 M_at_10:  0.022563676633444076 p_at_20:  0.0063 M_at_20:  0.02257760924925588 G_at_20 0.042597488833329235\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 45 p_at_10:  0.0065 G_at_10 0.02792095697122502 M_at_10:  0.017111480251015134 p_at_20:  0.0056 M_at_20:  0.019665306194033966 G_at_20 0.038284684695588815\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 46 p_at_10:  0.0088 G_at_10 0.04687089201693243 M_at_10:  0.03617571059431524 p_at_20:  0.0067 M_at_20:  0.0385313090921846 G_at_20 0.05569516945643141\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 47 p_at_10:  0.0079 G_at_10 0.034290394677567025 M_at_10:  0.021026208933185676 p_at_20:  0.0065 M_at_20:  0.023938566933022976 G_at_20 0.04512357712284085\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 48 p_at_10:  0.0042 G_at_10 0.02081094180826049 M_at_10:  0.014902177925433741 p_at_20:  0.0047 M_at_20:  0.016135909034605846 G_at_20 0.031537378864198065\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 49 p_at_10:  0.007 G_at_10 0.03591165947753591 M_at_10:  0.02712993724621631 p_at_20:  0.0056 M_at_20:  0.02937162490712062 G_at_20 0.04512819036665668\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 50 p_at_10:  0.0084 G_at_10 0.04250609492897888 M_at_10:  0.03127537836840163 p_at_20:  0.007 M_at_20:  0.034684020649712925 G_at_20 0.05602567646847865\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 51 p_at_10:  0.0065 G_at_10 0.022812160461630468 M_at_10:  0.012609819121447029 p_at_20:  0.0067 M_at_20:  0.01664644670854621 G_at_20 0.03899159630983459\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 52 p_at_10:  0.0079 G_at_10 0.034500683280423945 M_at_10:  0.022093023255813953 p_at_20:  0.0058 M_at_20:  0.022223234941393194 G_at_20 0.04150212383376133\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 53 p_at_10:  0.006 G_at_10 0.025732107244891955 M_at_10:  0.017344038390550015 p_at_20:  0.0067 M_at_20:  0.020914595740177136 G_at_20 0.04184039361053207\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 54 p_at_10:  0.0037 G_at_10 0.020346671065842044 M_at_10:  0.016162790697674418 p_at_20:  0.0049 M_at_20:  0.020074901159032488 G_at_20 0.03526803990356253\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 55 p_at_10:  0.0065 G_at_10 0.03310917890804795 M_at_10:  0.023279808047249904 p_at_20:  0.0063 M_at_20:  0.025731457984499956 G_at_20 0.04463073491920213\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 56 p_at_10:  0.0056 G_at_10 0.03145608199354014 M_at_10:  0.02543927648578811 p_at_20:  0.0051 M_at_20:  0.026785714285714284 G_at_20 0.040255955535728576\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 57 p_at_10:  0.0056 G_at_10 0.026936925716472975 M_at_10:  0.01928202288667405 p_at_20:  0.006 M_at_20:  0.020337998934370164 G_at_20 0.03947276207753545\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 58 p_at_10:  0.006 G_at_10 0.029859609594792762 M_at_10:  0.02076042820228867 p_at_20:  0.0047 M_at_20:  0.0222755345429764 G_at_20 0.036801876771567085\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 59 p_at_10:  0.007 G_at_10 0.03256917335623004 M_at_10:  0.02160206718346253 p_at_20:  0.0053 M_at_20:  0.023983453846654942 G_at_20 0.04172579710592976\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 60 p_at_10:  0.006 G_at_10 0.026416473481067477 M_at_10:  0.017356958287190846 p_at_20:  0.0058 M_at_20:  0.02000268777070563 G_at_20 0.03777021608238687\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 61 p_at_10:  0.0051 G_at_10 0.029427039527776828 M_at_10:  0.022958656330749356 p_at_20:  0.0051 M_at_20:  0.02576451278499662 G_at_20 0.04007001157060948\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 62 p_at_10:  0.0074 G_at_10 0.038802925530801974 M_at_10:  0.029501661129568105 p_at_20:  0.0056 M_at_20:  0.029539740824930546 G_at_20 0.04569623455584125\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 63 p_at_10:  0.006 G_at_10 0.025077403266304674 M_at_10:  0.014721299372462162 p_at_20:  0.0058 M_at_20:  0.01777788700767317 G_at_20 0.03688837269560845\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 64 p_at_10:  0.0042 G_at_10 0.021364848844958702 M_at_10:  0.015413436692506461 p_at_20:  0.0049 M_at_20:  0.018814143552785646 G_at_20 0.03422760952491608\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 65 p_at_10:  0.0042 G_at_10 0.0230412618003993 M_at_10:  0.0172609819121447 p_at_20:  0.0047 M_at_20:  0.02060643612753196 G_at_20 0.03570984598538622\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 66 p_at_10:  0.0074 G_at_10 0.03390457080472289 M_at_10:  0.021794019933554815 p_at_20:  0.0063 M_at_20:  0.02494126826206169 G_at_20 0.0456596816739212\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 67 p_at_10:  0.0088 G_at_10 0.04396441918105083 M_at_10:  0.030664451827242523 p_at_20:  0.0065 M_at_20:  0.033278639485169834 G_at_20 0.05348500492876258\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 68 p_at_10:  0.0042 G_at_10 0.020856449195281984 M_at_10:  0.01448874123292728 p_at_20:  0.0058 M_at_20:  0.018522071563687226 G_at_20 0.038108005057289764\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 69 p_at_10:  0.0042 G_at_10 0.02119266231352961 M_at_10:  0.015173495754891101 p_at_20:  0.0056 M_at_20:  0.019593355980424883 G_at_20 0.03762735555317641\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 70 p_at_10:  0.0056 G_at_10 0.02457442245765983 M_at_10:  0.015000000000000001 p_at_20:  0.0051 M_at_20:  0.017800846164659254 G_at_20 0.03579198440284887\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 71 p_at_10:  0.0056 G_at_10 0.01924361100528025 M_at_10:  0.008744924326319676 p_at_20:  0.0053 M_at_20:  0.010747184671873274 G_at_20 0.028440089935433212\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 72 p_at_10:  0.0056 G_at_10 0.02525166271799575 M_at_10:  0.016186784791435954 p_at_20:  0.0063 M_at_20:  0.02045678148061329 G_at_20 0.04152606473895432\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n",
      "it 73 p_at_10:  0.0033 G_at_10 0.01534726004074572 M_at_10:  0.01020487264673311 p_at_20:  0.0056 M_at_20:  0.014960444152610613 G_at_20 0.033129443938978306\n",
      "max p_at_10  0.0093 p_at_20 0.0081 M_at_10 0.038925802879291246 M_at_20 0.04194841286424554 G_at_10 0.051635563621235975 G_at_20 0.06313388981204421\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5787582bac3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m              \u001b[0mcounter_brand_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter_class_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter_user_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m              \u001b[0mindex_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m              _, D_loss_now = sess.run([D_solver, D_loss], \n\u001b[0m\u001b[1;32m     40\u001b[0m                                       feed_dict={brand_id:train_brand_batch, class_id:train_class_batch, real_user_emb:train_user_emb_batch,\n\u001b[1;32m     41\u001b[0m                                                  \u001b[0mcounter_brand_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcounter_brand_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf_config = tf.compat.v1.ConfigProto()  \n",
    "tf_config.gpu_options.allow_growth = True  \n",
    "saver = tf.compat.v1.train.Saver(max_to_keep= 5)\n",
    "sess = tf.compat.v1.Session(config=tf_config) \n",
    "#sess = tf.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "batch_size = 1024\n",
    "c_batch_size = batch_size*2\n",
    "\n",
    "max_p_at_10 = 0\n",
    "max_p_at_20 = 0\n",
    "max_M_at_10 = 0\n",
    "max_M_at_20 = 0 \n",
    "max_G_at_10 = 0\n",
    "max_G_at_20 = 0\n",
    "p_10_to_save = []\n",
    "p_20_to_save = []\n",
    "M_10_to_save = []\n",
    "M_20_to_save = []\n",
    "G_10_to_save = []\n",
    "G_20_to_save = []\n",
    "\n",
    "'''train'''\n",
    "for it in range(150):\n",
    "    D_range = 4\n",
    "    G_range = 1   \n",
    "    for D_it in range(D_range):\n",
    "        index = 0\n",
    "        index_2 = 0\n",
    "        while index < 198488:\n",
    "             if index + batch_size <= 198488:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, index + batch_size)\n",
    "                 index = index + batch_size\n",
    "             else:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, 198488)\n",
    "                 index = 198488\n",
    "             counter_brand_batch, counter_class_batch, counter_user_batch = support.get_counter_batch(index_2, index_2 + c_batch_size)\n",
    "             index_2 = index_2 + c_batch_size\n",
    "             _, D_loss_now = sess.run([D_solver, D_loss], \n",
    "                                      feed_dict={brand_id:train_brand_batch, class_id:train_class_batch, real_user_emb:train_user_emb_batch,\n",
    "                                                 counter_brand_id:counter_brand_batch,\n",
    "                                                 counter_class_id:counter_class_batch, counter_user_emb:counter_user_batch})  \n",
    "  \n",
    "    for G_it in range(G_range):\n",
    "        index = 0\n",
    "        while index < 198488:\n",
    "             if index + batch_size <= 198488:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, index + batch_size)\n",
    "                 index = index + batch_size \n",
    "             else:\n",
    "                 train_item_batch, train_brand_batch, train_class_batch, train_user_emb_batch = support.get_batchdata(index, 198488)\n",
    "                 index = 198488\n",
    "             _, G_loss_now = sess.run([G_solver, G_loss], feed_dict={brand_id:train_brand_batch, class_id:train_class_batch}) \n",
    "\n",
    "    if it % 1 == 0:\n",
    "        test_item_batch, test_brand_batch, test_classid_batch = support.get_testdata()\n",
    "        test_G_user = sess.run(fake_user_emb, feed_dict={brand_id:test_brand_batch, class_id:test_classid_batch})\n",
    "\n",
    "        p_at_10,p_at_20,M_at_10,M_at_20,G_at_10,G_at_20 = support.test(test_item_batch, test_G_user)\n",
    "        if p_at_10 > max_p_at_10:           \n",
    "            saver.save(sess, \"model_lara/model.ckpt\", global_step=it,) \n",
    "            max_p_at_10 = p_at_10\n",
    "        p_10_to_save.append(p_at_10)\n",
    "        if p_at_20 > max_p_at_20:\n",
    "            max_p_at_20 = p_at_20\n",
    "        p_20_to_save.append(p_at_20)\n",
    "        if M_at_10 > max_M_at_10:\n",
    "            max_M_at_10 = M_at_10\n",
    "        M_10_to_save.append(M_at_10)\n",
    "        if M_at_20 > max_M_at_20:\n",
    "            max_M_at_20 = M_at_20\n",
    "        M_20_to_save.append(M_at_20)\n",
    "        if G_at_10 > max_G_at_10:\n",
    "            max_G_at_10 = G_at_10\n",
    "        G_10_to_save.append(G_at_10)\n",
    "        if G_at_20 > max_G_at_20:\n",
    "            max_G_at_20 = G_at_20\n",
    "        G_20_to_save.append(G_at_20)\n",
    "      \n",
    "        print('it', it, 'p_at_10: ', p_at_10,'G_at_10',G_at_10, 'M_at_10: ',M_at_10,'p_at_20: ', p_at_20,'M_at_20: ',M_at_20,'G_at_20',G_at_20)\n",
    "        print('max p_at_10 ', max_p_at_10, 'p_at_20', max_p_at_20,'M_at_10',max_M_at_10,'M_at_20',max_M_at_20,'G_at_10',max_G_at_10,'G_at_20',max_G_at_20)\n",
    "    if it % 100 == 0:\n",
    "        pd.DataFrame(p_10_to_save).to_csv('p10.csv')\n",
    "        pd.DataFrame(p_20_to_save).to_csv('p20.csv')\n",
    "        pd.DataFrame(M_10_to_save).to_csv('m10.csv')\n",
    "        pd.DataFrame(M_20_to_save).to_csv('m20.csv')\n",
    "        pd.DataFrame(G_10_to_save).to_csv('g10.csv')\n",
    "        pd.DataFrame(G_20_to_save).to_csv('g20.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
