{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd35441-cf1e-4359-b8a0-88918afec161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import orion_recommend\n",
    "from orion_recommend.models import HybridMatrixFactorizationModel as HMFModel\n",
    "from orion_recommend.models import MatrixFactorizationModel as MFModel\n",
    "from scipy import sparse as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from orion_recommend.datasets import DatasetMap, synthetic, utils, Encoder\n",
    "from orion.sources import S3Source\n",
    "from orion.sources.io import read_csv, write_csv\n",
    "from orion.sources import RedshiftSource\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from orion_recommend.evaluate import metrics\n",
    "import implicit\n",
    "import lightfm\n",
    "import evall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e0551a-b8ae-4ac1-9723-5b1f77df4ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_user_rec(item, sim_users, k):\n",
    "    count = 0\n",
    "    for i, user_list in zip(item, sim_users):       \n",
    "        for u in user_list:\n",
    "            if ui_matrix[u,i] == 1:\n",
    "                count = count + 1            \n",
    "    p_at_k = round(count/(item.shape[0] * k), 4)\n",
    "\n",
    "    RS = []\n",
    "    ans = 0.0\n",
    "    for i, user_list in zip(item, sim_users):           \n",
    "        r=[]\n",
    "        for u in user_list:\n",
    "             r.append(ui_matrix[u][i])\n",
    "        ans = ans + evall.ndcg_at_k(r, k, method=1)\n",
    "        RS.append(r)\n",
    "    G_at_k = ans/item.shape[0]\n",
    "    M_at_k = evall.mean_average_precision(RS)\n",
    "    return p_at_k, G_at_k, M_at_k\n",
    "\n",
    "def metrics_item_rec(user, sim_items, k):\n",
    "    count = 0\n",
    "    for u, item_list in zip(user, sim_items):       \n",
    "        for i in item_list:\n",
    "            if ui_matrix[u,i] == 1:\n",
    "                count = count + 1            \n",
    "    p_at_k = round(count/(user.shape[0] * k), 4)\n",
    "\n",
    "    RS = []\n",
    "    ans = 0.0\n",
    "    for u, item_list in zip(user, sim_items):           \n",
    "        r=[]\n",
    "        for i in item_list:\n",
    "             r.append(ui_matrix[u][i])\n",
    "        ans = ans + evall.ndcg_at_k(r, k, method=1)\n",
    "        RS.append(r)\n",
    "    G_at_k = ans/user.shape[0]\n",
    "    M_at_k = evall.mean_average_precision(RS)\n",
    "    return p_at_k, G_at_k, M_at_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ae2a4-e632-4ef9-8696-ee59f8fe6d53",
   "metadata": {},
   "source": [
    "### Orion baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b05c94-37a1-4747-822f-9d469800fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_matrix= np.load(\"fa_ui_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d549f0d-d329-4663-9e69-0068ad663005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"users\", index_col= 0)\n",
    "items = pd.read_csv(\"items\", index_col= 0)\n",
    "interactions = pd.read_csv(\"interactions\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e16137-7543-476d-9fea-7d930b2a4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.user_id = users.user_id.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ab09cf-2af8-40fb-b8e8-5f506684ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.item_id = items.item_id.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a9a7f9-85f0-41d9-aad1-0415b2b41908",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = sp.csr_matrix(users)\n",
    "i = sp.csr_matrix(items)\n",
    "ints = sp.csr_matrix(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be024afb-159c-4092-84d2-ba38b6e1fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/evaluate/utils.py:176: UserWarning: The total number of users that can be sampled from for your test set is less than 75% of the available users. Consider reducing yourchosen 'n_test' (it is set to 1).\n",
      "  warnings.warn(\n",
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'customer_list' that are not in 'users'.\n",
      "  warnings.warn(\n",
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'inventory' that are not in 'items'.\n",
      "  warnings.warn(\n",
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'customer_list' that are not in 'users'.\n",
      "  warnings.warn(\n",
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'inventory' that are not in 'items'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, test = DatasetMap.split(interactions, users=users, items=items, frac_train=0.8, validate_inputs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19bd102e-baf2-4dca-a5f5-23ccb9956d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86284,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.encoded_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a61789-6622-4981-931c-f74c06153c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'inventory' that are not in 'items'.\n",
      "  warnings.warn(\n",
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'customer_list' that are not in 'users'.\n",
      "  warnings.warn(\n",
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/datasets/dataset_map.py:222: UserWarning: There are elements in 'inventory' that are not in 'items'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "opp, opp1 = DatasetMap.split(interactions.iloc[:,[1,0]], users=items, items=users, frac_train=0.8, validate_inputs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1eaf23-630b-4dd2-a745-7433c84f368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmod = HMFModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b188e45-d7cc-47ef-aee8-a5dad5f28ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "model = MFModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ff8999-654d-4560-ad90-1f95748cb5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<orion_recommend.models.hmf.HybridMatrixFactorizationModel at 0x7f152ee46310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmod.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443232a3-8b06-45c1-a4cc-86d6cf761a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f20be313a8e48dda0c456b2018fdc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<orion_recommend.models.mf.MatrixFactorizationModel at 0x7f152ee465e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4271f137-1540-4981-9813-4de08cbf0318",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "recommended_items_bpr = model.recommend(test.users, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "117a474e-e3d5-4dc0-9edb-b5d75df0e379",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recommending Chunk 0:  21%|██        | 1099/5189 [00:00<00:03, 1060.45it/s]\n",
      "Recommending Chunk 0:  23%|██▎       | 1212/5189 [00:00<00:03, 1027.80it/s]\n",
      "Recommending Chunk 0:  25%|██▌       | 1319/5189 [00:01<00:04, 967.05it/s] \n",
      "Recommending Chunk 0:  27%|██▋       | 1419/5189 [00:01<00:03, 945.58it/s][A\n",
      "Recommending Chunk 0:  29%|██▉       | 1515/5189 [00:01<00:03, 923.98it/s][A\n",
      "Recommending Chunk 0:  31%|███       | 1609/5189 [00:01<00:03, 902.60it/s][A\n",
      "Recommending Chunk 0:  33%|███▎      | 1708/5189 [00:01<00:03, 924.02it/s][A\n",
      "Recommending Chunk 0:  36%|███▋      | 1890/5189 [00:01<00:03, 868.25it/s][A\n",
      "Recommending Chunk 0:  38%|███▊      | 1979/5189 [00:01<00:03, 874.16it/s][A\n",
      "Recommending Chunk 0:  40%|███▉      | 2068/5189 [00:01<00:03, 878.12it/s][A\n",
      "Recommending Chunk 0:  42%|████▏     | 2157/5189 [00:02<00:03, 876.86it/s][A\n",
      "Recommending Chunk 1:  16%|█▌        | 829/5188 [00:01<00:06, 699.66it/s]\u001b[A\n",
      "Recommending Chunk 0:  43%|████▎     | 2245/5189 [00:02<00:03, 777.25it/s][A\n",
      "Recommending Chunk 0:  45%|████▍     | 2325/5189 [00:02<00:03, 760.39it/s][A\n",
      "Recommending Chunk 0:  47%|████▋     | 2422/5189 [00:02<00:03, 816.26it/s]\u001b[A\n",
      "Recommending Chunk 0:  48%|████▊     | 2506/5189 [00:02<00:03, 790.56it/s]\u001b[A\n",
      "Recommending Chunk 0:  50%|████▉     | 2594/5189 [00:02<00:03, 813.18it/s]\u001b[A\n",
      "Recommending Chunk 0:  52%|█████▏    | 2679/5189 [00:02<00:03, 822.05it/s]\u001b[A\n",
      "Recommending Chunk 0:  53%|█████▎    | 2762/5189 [00:02<00:02, 822.46it/s]\u001b[A\n",
      "Recommending Chunk 0:  57%|█████▋    | 2943/5189 [00:03<00:02, 859.32it/s]\u001b[A\n",
      "Recommending Chunk 0:  58%|█████▊    | 3030/5189 [00:03<00:02, 852.41it/s]\u001b[A\n",
      "Recommending Chunk 0:  60%|██████    | 3116/5189 [00:03<00:02, 849.13it/s]\u001b[A\n",
      "Recommending Chunk 0:  62%|██████▏   | 3202/5189 [00:03<00:02, 850.34it/s]\u001b[A\n",
      "Recommending Chunk 0:  63%|██████▎   | 3292/5189 [00:03<00:02, 863.96it/s]\u001b[A\n",
      "Recommending Chunk 0:  65%|██████▌   | 3380/5189 [00:03<00:02, 867.06it/s]\u001b[A\n",
      "Recommending Chunk 0:  67%|██████▋   | 3476/5189 [00:03<00:01, 893.02it/s]\u001b[A\n",
      "Recommending Chunk 0:  69%|██████▉   | 3574/5189 [00:03<00:01, 916.76it/s]\u001b[A\n",
      "Recommending Chunk 0:  71%|███████   | 3666/5189 [00:03<00:01, 914.90it/s]\u001b[A\n",
      "Recommending Chunk 0:  73%|███████▎  | 3764/5189 [00:03<00:01, 931.93it/s]\u001b[A\n",
      "Recommending Chunk 0:  74%|███████▍  | 3865/5189 [00:04<00:01, 954.82it/s]\u001b[A\n",
      "Recommending Chunk 0:  76%|███████▋  | 3962/5189 [00:04<00:01, 957.63it/s]\u001b[A\n",
      "Recommending Chunk 0:  78%|███████▊  | 4059/5189 [00:04<00:01, 959.16it/s]\u001b[A\n",
      "Recommending Chunk 0:  80%|████████  | 4155/5189 [00:04<00:01, 908.05it/s]\u001b[A\n",
      "Recommending Chunk 1:  49%|████▉     | 2539/5188 [00:03<00:03, 767.49it/s]\u001b[A\n",
      "Recommending Chunk 0:  82%|████████▏ | 4247/5189 [00:04<00:01, 793.39it/s]\u001b[A\n",
      "Recommending Chunk 0:  85%|████████▌ | 4422/5189 [00:04<00:00, 797.54it/s]\u001b[A\n",
      "Recommending Chunk 0:  87%|████████▋ | 4507/5189 [00:04<00:00, 811.22it/s]\u001b[A\n",
      "Recommending Chunk 0:  89%|████████▊ | 4597/5189 [00:04<00:00, 834.18it/s]\u001b[A\n",
      "Recommending Chunk 0:  90%|█████████ | 4682/5189 [00:05<00:00, 825.85it/s]\u001b[A\n",
      "Recommending Chunk 0:  92%|█████████▏| 4766/5189 [00:05<00:00, 820.00it/s]\u001b[A\n",
      "Recommending Chunk 1:  59%|█████▉    | 3082/5188 [00:04<00:03, 700.15it/s]\u001b[A\n",
      "Recommending Chunk 0:  93%|█████████▎| 4849/5189 [00:05<00:00, 737.82it/s]\u001b[A\n",
      "Recommending Chunk 0:  95%|█████████▌| 4942/5189 [00:05<00:00, 785.51it/s]\u001b[A\n",
      "Recommending Chunk 0:  97%|█████████▋| 5023/5189 [00:05<00:00, 733.36it/s]\u001b[A\n",
      "Recommending Chunk 0:  98%|█████████▊| 5103/5189 [00:05<00:00, 749.14it/s]\u001b[A\n",
      "Recommending Chunk 0: 100%|██████████| 5189/5189 [00:05<00:00, 897.45it/s]\u001b[A\n",
      "\n",
      "Recommending Chunk 1:  68%|██████▊   | 3528/5188 [00:04<00:02, 682.38it/s]\u001b[A\n",
      "Recommending Chunk 1:  70%|██████▉   | 3630/5188 [00:04<00:02, 778.34it/s]\u001b[A\n",
      "Recommending Chunk 1:  72%|███████▏  | 3710/5188 [00:05<00:01, 782.66it/s]\u001b[A\n",
      "Recommending Chunk 1:  73%|███████▎  | 3800/5188 [00:05<00:01, 815.01it/s]\u001b[A\n",
      "Recommending Chunk 1:  75%|███████▍  | 3889/5188 [00:05<00:01, 834.79it/s]\u001b[A\n",
      "Recommending Chunk 1:  77%|███████▋  | 4002/5188 [00:05<00:01, 920.64it/s]\u001b[A\n",
      "Recommending Chunk 1:  81%|████████  | 4184/5188 [00:05<00:00, 1186.35it/s]\u001b[A\n",
      "Recommending Chunk 1:  84%|████████▍ | 4361/5188 [00:05<00:00, 1359.04it/s]\u001b[A\n",
      "Recommending Chunk 1:  87%|████████▋ | 4536/5188 [00:05<00:00, 1473.67it/s]\u001b[A\n",
      "Recommending Chunk 1:  91%|█████████ | 4716/5188 [00:05<00:00, 1568.41it/s]\u001b[A\n",
      "Recommending Chunk 1:  94%|█████████▍| 4896/5188 [00:05<00:00, 1635.63it/s]\u001b[A\n",
      "Recommending Chunk 1: 100%|██████████| 5188/5188 [00:06<00:00, 855.54it/s] \u001b[A\n",
      "Recommending Chunk 0:  14%|█▍        | 722/5189 [00:00<00:03, 1428.40it/s]\n",
      "Recommending Chunk 0:  17%|█▋        | 874/5189 [00:00<00:03, 1231.93it/s]\n",
      "Recommending Chunk 1:   2%|▏         | 99/5188 [00:00<00:05, 982.45it/s]\u001b[A\n",
      "Recommending Chunk 0:  19%|█▉        | 1006/5189 [00:00<00:04, 938.90it/s][A\n",
      "Recommending Chunk 0:  21%|██▏       | 1113/5189 [00:00<00:04, 896.64it/s][A\n",
      "Recommending Chunk 0:  23%|██▎       | 1211/5189 [00:01<00:04, 823.50it/s][A\n",
      "Recommending Chunk 1:   9%|▊         | 453/5188 [00:00<00:06, 764.08it/s]\u001b[A\n",
      "Recommending Chunk 0:  25%|██▌       | 1299/5189 [00:01<00:05, 756.87it/s][A\n",
      "Recommending Chunk 0:  27%|██▋       | 1378/5189 [00:01<00:05, 727.01it/s][A\n",
      "Recommending Chunk 0:  28%|██▊       | 1453/5189 [00:01<00:05, 727.30it/s][A\n",
      "Recommending Chunk 0:  30%|██▉       | 1536/5189 [00:01<00:04, 750.90it/s][A\n",
      "Recommending Chunk 0:  31%|███       | 1613/5189 [00:01<00:04, 727.56it/s][A\n",
      "Recommending Chunk 0:  33%|███▎      | 1687/5189 [00:01<00:04, 726.22it/s][A\n",
      "Recommending Chunk 0:  34%|███▍      | 1763/5189 [00:01<00:04, 734.10it/s][A\n",
      "Recommending Chunk 0:  35%|███▌      | 1837/5189 [00:02<00:04, 714.38it/s]\u001b[A\n",
      "Recommending Chunk 0:  37%|███▋      | 1926/5189 [00:02<00:04, 762.74it/s]\u001b[A\n",
      "Recommending Chunk 0:  39%|███▉      | 2017/5189 [00:02<00:03, 804.12it/s]\u001b[A\n",
      "Recommending Chunk 0:  40%|████      | 2099/5189 [00:02<00:04, 716.74it/s]\u001b[A\n",
      "Recommending Chunk 0:  42%|████▏     | 2173/5189 [00:02<00:04, 683.49it/s]\u001b[A\n",
      "Recommending Chunk 0:  43%|████▎     | 2243/5189 [00:02<00:04, 682.04it/s]\u001b[A\n",
      "Recommending Chunk 0:  46%|████▋     | 2407/5189 [00:02<00:02, 943.58it/s]\u001b[A\n",
      "Recommending Chunk 0:  50%|████▉     | 2584/5189 [00:02<00:02, 1173.55it/s][A\n",
      "Recommending Chunk 0:  52%|█████▏    | 2706/5189 [00:02<00:02, 1046.84it/s][A\n",
      "Recommending Chunk 0:  54%|█████▍    | 2816/5189 [00:03<00:02, 986.70it/s] [A\n",
      "Recommending Chunk 1:  33%|███▎      | 1735/5188 [00:02<00:05, 649.75it/s]\u001b[A\n",
      "Recommending Chunk 0:  56%|█████▋    | 2919/5189 [00:03<00:02, 919.35it/s]\u001b[A\n",
      "Recommending Chunk 0:  58%|█████▊    | 3014/5189 [00:03<00:02, 809.76it/s]\u001b[A\n",
      "Recommending Chunk 0:  60%|█████▉    | 3099/5189 [00:03<00:02, 797.74it/s]\u001b[A\n",
      "Recommending Chunk 0:  61%|██████▏   | 3182/5189 [00:03<00:02, 739.11it/s]\u001b[A\n",
      "Recommending Chunk 0:  63%|██████▎   | 3258/5189 [00:03<00:02, 715.43it/s]\u001b[A\n",
      "Recommending Chunk 0:  64%|██████▍   | 3333/5189 [00:03<00:02, 723.32it/s]\u001b[A\n",
      "Recommending Chunk 0:  66%|██████▌   | 3407/5189 [00:03<00:02, 703.75it/s]\u001b[A\n",
      "Recommending Chunk 0:  67%|██████▋   | 3483/5189 [00:04<00:02, 718.43it/s]\u001b[A\n",
      "Recommending Chunk 0:  69%|██████▊   | 3558/5189 [00:04<00:02, 725.99it/s]\u001b[A\n",
      "Recommending Chunk 0:  70%|███████   | 3636/5189 [00:04<00:02, 740.35it/s]\u001b[A\n",
      "Recommending Chunk 0:  72%|███████▏  | 3714/5189 [00:04<00:01, 750.98it/s]\u001b[A\n",
      "Recommending Chunk 0:  73%|███████▎  | 3797/5189 [00:04<00:01, 771.97it/s]\u001b[A\n",
      "Recommending Chunk 0:  75%|███████▍  | 3880/5189 [00:04<00:01, 788.93it/s]\u001b[A\n",
      "Recommending Chunk 1:  54%|█████▍    | 2801/5188 [00:03<00:03, 754.72it/s]\u001b[A\n",
      "Recommending Chunk 0:  76%|███████▋  | 3960/5189 [00:04<00:01, 776.85it/s]\u001b[A\n",
      "Recommending Chunk 0:  78%|███████▊  | 4038/5189 [00:04<00:01, 689.00it/s]\u001b[A\n",
      "Recommending Chunk 0:  79%|███████▉  | 4109/5189 [00:04<00:01, 691.78it/s]\u001b[A\n",
      "Recommending Chunk 0:  81%|████████▏ | 4218/5189 [00:05<00:01, 801.49it/s]\u001b[A\n",
      "Recommending Chunk 0:  83%|████████▎ | 4300/5189 [00:05<00:01, 806.02it/s]\u001b[A\n",
      "Recommending Chunk 0:  84%|████████▍ | 4382/5189 [00:05<00:01, 688.94it/s]\u001b[A\n",
      "Recommending Chunk 0:  86%|████████▌ | 4457/5189 [00:05<00:01, 703.34it/s]\u001b[A\n",
      "Recommending Chunk 0:  87%|████████▋ | 4531/5189 [00:05<00:00, 701.27it/s]\u001b[A\n",
      "Recommending Chunk 0:  89%|████████▊ | 4604/5189 [00:05<00:00, 653.61it/s]\u001b[A\n",
      "Recommending Chunk 0:  90%|█████████ | 4684/5189 [00:05<00:00, 691.38it/s]\u001b[A\n",
      "Recommending Chunk 0:  92%|█████████▏| 4757/5189 [00:05<00:00, 700.59it/s]\u001b[A\n",
      "Recommending Chunk 0:  93%|█████████▎| 4829/5189 [00:05<00:00, 697.76it/s]\u001b[A\n",
      "Recommending Chunk 0:  95%|█████████▍| 4905/5189 [00:06<00:00, 714.76it/s]\u001b[A\n",
      "Recommending Chunk 0:  96%|█████████▌| 4978/5189 [00:06<00:00, 701.69it/s]\u001b[A\n",
      "Recommending Chunk 0:  97%|█████████▋| 5057/5189 [00:06<00:00, 724.99it/s]\u001b[A\n",
      "Recommending Chunk 0: 100%|██████████| 5189/5189 [00:06<00:00, 817.26it/s]\u001b[A\n",
      "\n",
      "Recommending Chunk 1:  80%|████████  | 4174/5188 [00:05<00:01, 765.47it/s]\u001b[A\n",
      "Recommending Chunk 1:  82%|████████▏ | 4251/5188 [00:05<00:01, 759.33it/s]\u001b[A\n",
      "Recommending Chunk 1:  86%|████████▌ | 4437/5188 [00:06<00:00, 1080.84it/s]\u001b[A\n",
      "Recommending Chunk 1:  88%|████████▊ | 4546/5188 [00:06<00:00, 1011.68it/s]\u001b[A\n",
      "Recommending Chunk 1:  90%|████████▉ | 4649/5188 [00:06<00:00, 993.11it/s] \u001b[A\n",
      "Recommending Chunk 1:  92%|█████████▏| 4750/5188 [00:06<00:00, 917.82it/s]\u001b[A\n",
      "Recommending Chunk 1:  93%|█████████▎| 4844/5188 [00:06<00:00, 885.94it/s]\u001b[A\n",
      "Recommending Chunk 1:  95%|█████████▌| 4934/5188 [00:06<00:00, 751.94it/s]\u001b[A\n",
      "Recommending Chunk 1: 100%|██████████| 5188/5188 [00:06<00:00, 761.24it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "preds_10 = model.predict(test.items,n=10)\n",
    "preds_20 =  model.predict(test.items,n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bad7df-942b-46b7-8b09-d33d6f1af4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_10_arr = np.array(list(preds_10.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b4d610-3a4e-465a-b497-f46c0bd412fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declanbarrycbc1/thesis/src/orion-recommend/orion_recommend/evaluate/metrics.py:151: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if element in actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_at_k(test.items,preds_10_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b8bfab-5d89-459f-b926-1b840c5466fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid type passed to user_ids parameter. This must be either int or np.int32 array. Type received: <class 'numpy.int64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-154749b86c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(hmod.score(test,train, k=10, fn=metrics.ndcg),\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_at_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.score(test, train, k=20, fn=metrics.precision_at_k))\n",
      "\u001b[0;32m~/thesis/src/orion-recommend/orion_recommend/models/hmf.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, test, train, fn, k, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         recs = np.asarray(\n\u001b[0;32m---> 67\u001b[0;31m             [\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank_items_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/src/orion-recommend/orion_recommend/models/hmf.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m         recs = np.asarray(\n\u001b[1;32m     67\u001b[0m             [\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank_items_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             ]\n",
      "\u001b[0;32m~/thesis/src/orion-recommend/orion_recommend/models/hmf.py\u001b[0m in \u001b[0;36m_rank_items_single\u001b[0;34m(self, user, selected)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_rank_items_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         scores = self._model.predict(\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mselected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user_ids, item_ids, item_features, user_features, num_threads)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    789\u001b[0m                 \u001b[0;34mf\"Invalid type passed to user_ids parameter. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0;34mf\"This must be either int or np.int32 array. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid type passed to user_ids parameter. This must be either int or np.int32 array. Type received: <class 'numpy.int64'>"
     ]
    }
   ],
   "source": [
    "print(hmod.score(test,train, k=10, fn=metrics.ndcg),\n",
    "model.score(test, train, k=10, fn=metrics.precision_at_k),\n",
    "     model.score(test,train, k=20, fn=metrics.ndcg),\n",
    "model.score(test, train, k=20, fn=metrics.precision_at_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f5d3b73-4357-40fe-9805-746f2707478e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03450249835621144 0.2907692307692308 0.03306735631791807 0.2907692307692308\n"
     ]
    }
   ],
   "source": [
    "print(model.score(test,train, k=10, fn=metrics.ndcg),\n",
    "model.score(test, train, k=10, fn=metrics.precision_at_k),\n",
    "     model.score(test,train, k=20, fn=metrics.ndcg),\n",
    "model.score(test, train, k=20, fn=metrics.precision_at_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2b51a-93eb-43ea-8802-65e9552a1a2f",
   "metadata": {},
   "source": [
    "### Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d295f49-0019-43be-afd2-f879a23df430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43236da98b62454e90cfa84e33aca673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<orion_recommend.models.mf.MatrixFactorizationModel at 0x7fe6068db760>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54bf7280-8edf-4513-bc1b-f752b4fd8215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recommending Chunk 0: 100%|██████████| 10377/10377 [00:20<00:00, 506.83it/s]\n"
     ]
    }
   ],
   "source": [
    "recs = model.recommend(opp.users, chunk_size = 20000,n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5176d5ba-0b3e-4ac6-ae8a-91a77ebf3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = recommended_items_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08cef0d3-4385-4363-8445-18e8f50cbb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array([*recs.values()])\n",
    "sim_users = np.array([*recs.values()])\n",
    "sim_users = [list(map(int, sim_users[i])) for i in range(sim_users.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72a28231-7699-4d7e-bfae-bde99198d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86284, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sim_users).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31809696-a80f-454f-bf84-06de9c978576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0005, 0.002309164708751765, 0.0014138663902814846)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_item_rec(test.users, sim_users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806306f1-2e60-4d9b-9dc6-8896320ffce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012423852729491474 0.012180974477958236 0.0013672086866157247 0.012180974477958236\n"
     ]
    }
   ],
   "source": [
    "print(model.score(opp1,opp, k=10, fn=metrics.ndcg),\n",
    "model.score(opp1, opp, k=10, fn=metrics.precision_at_k),\n",
    "     model.score(opp1,opp, k=20, fn=metrics.ndcg),\n",
    "model.score(opp1, opp, k=20, fn=metrics.precision_at_k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
